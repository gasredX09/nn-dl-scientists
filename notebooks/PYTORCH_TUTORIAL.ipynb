{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHnQTYUwoh3l"
      },
      "source": [
        "# **What is Pytorch?**\n",
        "\n",
        "Pytorch is a python-based scientific computing package targeted for\n",
        "\n",
        "1.   replacement for NumPy to use the power of GPUs\n",
        "2.   deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **What is a Tensor?**\n",
        "\n",
        "Similar to NumPyâ€™s ndarrays, but can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_FbK8f7pWPJ",
        "outputId": "9254c39f-9b14-4140-98c6-52e40ea18cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8087, 0.4726, 0.2960],\n",
            "        [0.9052, 0.0918, 0.8315],\n",
            "        [0.2257, 0.5987, 0.0036],\n",
            "        [0.0087, 0.7708, 0.7121],\n",
            "        [0.0295, 0.5055, 0.1698]])\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9v4GRlApmWP"
      },
      "source": [
        "A tensor can have different datatypes;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbAFbE7p23C",
        "outputId": "6e6cab7c-e040-4f9b-c1d4-be46cdd9c845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "x datatype: torch.int64\n",
            "x:  tensor([[0, 0, 0]])\n",
            "\n",
            "y datatype: torch.float32\n",
            "y:  tensor([[0., 0., 0.]])\n",
            "\n",
            "z datatype: torch.float64\n",
            "z:  tensor([[0., 0., 0.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(1, 3, dtype=torch.long)\n",
        "print(\"\\nx datatype:\",x.dtype)\n",
        "print(\"x: \", x)\n",
        "\n",
        "y = torch.zeros(1, 3, dtype=torch.float)\n",
        "print(\"\\ny datatype:\", y.dtype)\n",
        "print(\"y: \", y)\n",
        "\n",
        "z = torch.zeros(1, 3, dtype=torch.double)\n",
        "print(\"\\nz datatype:\",z.dtype)\n",
        "print(\"z: \", z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htdXJDfmrW7z"
      },
      "source": [
        "A tensor can be constructed\n",
        "1. directly from data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG2VP9mIrXva",
        "outputId": "9442c572-60c7-455b-a702-8dc5bf7eb288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_moo-Ur0CF"
      },
      "source": [
        "2. based on an existing tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXK9xWXqr_bk",
        "outputId": "d464bd27-6567-4761-a8b9-e3c14c52320e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-1.4042, -1.1507,  0.3450],\n",
            "        [ 0.5354,  1.6805, -0.7699]], dtype=torch.float64)\n",
            "tensor([[ 0.1071, -0.6353, -1.0145],\n",
            "        [-0.2794, -0.4673,  0.3808]])\n",
            "\n",
            "Size of the tensors:\n",
            " torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "y = torch.randn_like(x)                       #result will have the same size\n",
        "print(y)\n",
        "\n",
        "z = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
        "print(z)\n",
        "\n",
        "#get sizes of tensors;\n",
        "\n",
        "print(\"\\nSize of the tensors:\\n\",x.size(), y.size(), z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff_W4iyarZnH"
      },
      "source": [
        "Tensor indexing is similar to numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2c5ozMprdw7",
        "outputId": "2f01f5b1-608f-48db-cd1f-30d723610b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tensor x:\n",
            "tensor([[[7, 3, 9, 9, 4],\n",
            "         [9, 3, 0, 0, 0],\n",
            "         [9, 8, 0, 1, 2],\n",
            "         [0, 3, 6, 5, 9]],\n",
            "\n",
            "        [[0, 1, 3, 4, 9],\n",
            "         [2, 7, 2, 8, 1],\n",
            "         [3, 3, 9, 8, 8],\n",
            "         [4, 6, 4, 6, 6]],\n",
            "\n",
            "        [[7, 5, 3, 3, 2],\n",
            "         [4, 9, 2, 5, 5],\n",
            "         [1, 9, 8, 4, 5],\n",
            "         [9, 0, 0, 9, 7]]])\n",
            "\n",
            "\n",
            "x[0][0][0]\n",
            " tensor(7)\n",
            "x[1,2,3]\n",
            " tensor(8)\n",
            "x[-1,-1][2]\n",
            " tensor(0)\n",
            "x[-1,-1][-1]\n",
            " tensor(7)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Basic\n",
        "x = torch.randint(0,10,size=(3,4,5)) # 3D tensor\n",
        "\n",
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "# Some valid ways of accessing individual elements in the tensor\n",
        "print('x[0][0][0]\\n', x[0][0][0])\n",
        "print('x[1,2,3]\\n', x[1,2,3])\n",
        "print('x[-1,-1][2]\\n', x[-1,-1][2])\n",
        "print('x[-1,-1][-1]\\n', x[-1,-1][-1])\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZXfkOBsO1c"
      },
      "source": [
        "Tensors can be sliced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQNSOtIqsRtE",
        "outputId": "0467a3a1-6a61-43a2-b9d9-a4408ff048de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tensor x:\n",
            "tensor([[[7, 3, 9, 9, 4],\n",
            "         [9, 3, 0, 0, 0],\n",
            "         [9, 8, 0, 1, 2],\n",
            "         [0, 3, 6, 5, 9]],\n",
            "\n",
            "        [[0, 1, 3, 4, 9],\n",
            "         [2, 7, 2, 8, 1],\n",
            "         [3, 3, 9, 8, 8],\n",
            "         [4, 6, 4, 6, 6]],\n",
            "\n",
            "        [[7, 5, 3, 3, 2],\n",
            "         [4, 9, 2, 5, 5],\n",
            "         [1, 9, 8, 4, 5],\n",
            "         [9, 0, 0, 9, 7]]])\n",
            "\n",
            "\n",
            "x[0] (first dim.) \n",
            " torch.Size([4, 5]) \n",
            " tensor([[7, 3, 9, 9, 4],\n",
            "        [9, 3, 0, 0, 0],\n",
            "        [9, 8, 0, 1, 2],\n",
            "        [0, 3, 6, 5, 9]])\n",
            "x[:1] (first dim.) \n",
            " torch.Size([1, 4, 5]) \n",
            " tensor([[[7, 3, 9, 9, 4],\n",
            "         [9, 3, 0, 0, 0],\n",
            "         [9, 8, 0, 1, 2],\n",
            "         [0, 3, 6, 5, 9]]])\n",
            "x[:,1] (all dim. row=1) \n",
            " tensor([[9, 3, 0, 0, 0],\n",
            "        [2, 7, 2, 8, 1],\n",
            "        [4, 9, 2, 5, 5]])\n",
            "x[:,:,3] (all dim. all rows but only 3rd column) \n",
            " torch.Size([3, 4]) \n",
            " tensor([[9, 0, 1, 5],\n",
            "        [4, 8, 8, 6],\n",
            "        [3, 5, 4, 9]])\n",
            "x[:,:,-2:] (all dim., all rows but last 2 columns) \n",
            " torch.Size([3, 4, 2]) \n",
            " tensor([[[9, 4],\n",
            "         [0, 0],\n",
            "         [1, 2],\n",
            "         [5, 9]],\n",
            "\n",
            "        [[4, 9],\n",
            "         [8, 1],\n",
            "         [8, 8],\n",
            "         [6, 6]],\n",
            "\n",
            "        [[3, 2],\n",
            "         [5, 5],\n",
            "         [4, 5],\n",
            "         [9, 7]]])\n"
          ]
        }
      ],
      "source": [
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "print('x[0] (first dim.) \\n', x[0].shape,'\\n',x[0])\n",
        "print('x[:1] (first dim.) \\n', x[:1].shape,'\\n',x[:1])\n",
        "print('x[:,1] (all dim. row=1) \\n', x[:,1])\n",
        "print('x[:,:,3] (all dim. all rows but only 3rd column) \\n', x[:,:,3].shape,'\\n',x[:,:,3])\n",
        "print('x[:,:,-2:] (all dim., all rows but last 2 columns) \\n',x[:,:,-2:].shape,'\\n', x[:,:,-2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vODYPzjYvAyb"
      },
      "source": [
        "---\n",
        "# **Tensor Operations:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b_RDkeU-Qf6"
      },
      "source": [
        "##Operations can be performed with different syntaxes. For addition;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3lJAJDvSVc",
        "outputId": "2156c615-ea12-458d-bdea-13835577f4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1143, -0.3422, -1.5102],\n",
            "        [-0.2599,  0.4454,  0.3359]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 1:\n",
        "x = torch.rand(2, 3)\n",
        "y = torch.randn_like(x)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBFY3Bdvvhbz",
        "outputId": "6f55e075-1ea8-4333-d032-1933ed0bdffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1143, -0.3422, -1.5102],\n",
            "        [-0.2599,  0.4454,  0.3359]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 2:\n",
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcAIOqwYv7W_",
        "outputId": "44afcd97-1d1d-4417-e1ac-87a09323a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.3378, -0.6942, -2.0378],\n",
            "        [-0.6628, -0.5455, -0.0611]])\n",
            "tensor([[-1.1143, -0.3422, -1.5102],\n",
            "        [-0.2599,  0.4454,  0.3359]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 4: in-place, post-fixed with an _\n",
        "print(y)\n",
        "\n",
        "y.add_(x)\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZPa1sZvrSN",
        "outputId": "e5781dab-c7fd-4e1f-e980-ec6c7c07bdeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8907,  0.0099, -0.9825],\n",
              "        [ 0.1429,  1.4362,  0.7329]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#syntax 3: an output tensor as argument\n",
        "result = torch.empty(2, 3)\n",
        "print(result)\n",
        "torch.add(x, y, out=result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-grS8Y8M9QJp"
      },
      "source": [
        "##Reduction operations (sum(), mean(), std(), max(), argmax(), prod(), unique() etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YD5yiV59SYh",
        "outputId": "d73a6b5b-ba2b-4e7e-c56d-4b0282ea5124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "original x1:\n",
            "tensor([1., 1., 1.])\n",
            "\n",
            "original x2:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "x1.sum()\n",
            "tensor(3.)\n",
            "tensor(3.)\n",
            "\n",
            "x2.sum()\n",
            "tensor(12.)\n",
            "tensor(12.)\n",
            "\n",
            "x2.sum(axis=0)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "\n",
            "x2.sum(axis=1)\n",
            "tensor([4., 4., 4.])\n",
            "tensor([4., 4., 4.])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.ones(3)\n",
        "x2 = torch.ones(size=(3,4))\n",
        "\n",
        "print('\\noriginal x1:')\n",
        "print(x1)\n",
        "\n",
        "print('\\noriginal x2:')\n",
        "print(x2)\n",
        "\n",
        "print('\\nx1.sum()')\n",
        "print(x1.sum())\n",
        "print(torch.sum(x1))\n",
        "\n",
        "print('\\nx2.sum()')\n",
        "print(x2.sum())\n",
        "print(torch.sum(x2))\n",
        "\n",
        "print('\\nx2.sum(axis=0)')\n",
        "print(x2.sum(axis=0))\n",
        "print(torch.sum(x2, axis=0))\n",
        "\n",
        "print('\\nx2.sum(axis=1)')\n",
        "print(x2.sum(axis=1))\n",
        "print(torch.sum(x2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzc332nH9pjl"
      },
      "source": [
        "---\n",
        "# **Handling Tensors:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMXNsgRbxbWg"
      },
      "source": [
        "## Resize/reshape a tensor with `torch.view` and `torch.reshape`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QF0sEQ03KuV"
      },
      "source": [
        "### torch.view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rrCRqC7xx-R",
        "outputId": "575c1535-b158-476a-9e43-7a25bf17bf26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([[-0.5135,  0.2299, -0.7517, -0.5847],\n",
            "        [ 0.7409,  0.0925, -1.3172, -1.6695],\n",
            "        [ 0.6125,  1.1950, -0.5464, -2.3114],\n",
            "        [ 0.0335,  0.0708,  0.4559, -0.5392]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd3WhxCz3Nmk"
      },
      "source": [
        "### torch.reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38EaRsiCycKK",
        "outputId": "32afdbf0-6cdf-4f75-92d2-7e0d030c26ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orginal tensor shape:  torch.Size([3, 4, 5])\n",
            "Orginal tensor: \n",
            "tensor([[[51, 70, 80, 36, 32],\n",
            "         [60, 87, 10, 16, 87],\n",
            "         [52, 89,  3, 54, 18],\n",
            "         [45, 79, 14, 18, 68]],\n",
            "\n",
            "        [[64, 52, 62, 19, 29],\n",
            "         [78, 88, 97, 89, 14],\n",
            "         [57, 84, 43,  1, 53],\n",
            "         [99, 69, 61, 81, 39]],\n",
            "\n",
            "        [[54, 45,  8, 38,  6],\n",
            "         [87, 67, 13, 43, 42],\n",
            "         [63, 86, 25, 89, 51],\n",
            "         [10, 67, 97, 23, 31]]])\n",
            "\n",
            "\n",
            "----------------\n",
            "Shape to have 12 rows and 5 columns (x.reshape((12,5))): \n",
            "\n",
            "tensor([[51, 70, 80, 36, 32],\n",
            "        [60, 87, 10, 16, 87],\n",
            "        [52, 89,  3, 54, 18],\n",
            "        [45, 79, 14, 18, 68],\n",
            "        [64, 52, 62, 19, 29],\n",
            "        [78, 88, 97, 89, 14],\n",
            "        [57, 84, 43,  1, 53],\n",
            "        [99, 69, 61, 81, 39],\n",
            "        [54, 45,  8, 38,  6],\n",
            "        [87, 67, 13, 43, 42],\n",
            "        [63, 86, 25, 89, 51],\n",
            "        [10, 67, 97, 23, 31]]) torch.Size([12, 5])\n",
            "\n",
            "\n",
            "----------------\n",
            "Shape to have 10 rows and using -1 to infer based on the elements in other dimensions (x.reshape(10,-1)): \n",
            "\n",
            "tensor([[51, 70, 80, 36, 32, 60],\n",
            "        [87, 10, 16, 87, 52, 89],\n",
            "        [ 3, 54, 18, 45, 79, 14],\n",
            "        [18, 68, 64, 52, 62, 19],\n",
            "        [29, 78, 88, 97, 89, 14],\n",
            "        [57, 84, 43,  1, 53, 99],\n",
            "        [69, 61, 81, 39, 54, 45],\n",
            "        [ 8, 38,  6, 87, 67, 13],\n",
            "        [43, 42, 63, 86, 25, 89],\n",
            "        [51, 10, 67, 97, 23, 31]]) torch.Size([10, 6])\n",
            "----------------\n",
            "\n",
            "\n",
            "Reshape to have 4 rows and 3 columns (x.reshape(5,4,3)): \n",
            "\n",
            "tensor([[[51, 70, 80],\n",
            "         [36, 32, 60],\n",
            "         [87, 10, 16],\n",
            "         [87, 52, 89]],\n",
            "\n",
            "        [[ 3, 54, 18],\n",
            "         [45, 79, 14],\n",
            "         [18, 68, 64],\n",
            "         [52, 62, 19]],\n",
            "\n",
            "        [[29, 78, 88],\n",
            "         [97, 89, 14],\n",
            "         [57, 84, 43],\n",
            "         [ 1, 53, 99]],\n",
            "\n",
            "        [[69, 61, 81],\n",
            "         [39, 54, 45],\n",
            "         [ 8, 38,  6],\n",
            "         [87, 67, 13]],\n",
            "\n",
            "        [[43, 42, 63],\n",
            "         [86, 25, 89],\n",
            "         [51, 10, 67],\n",
            "         [97, 23, 31]]]) torch.Size([5, 4, 3])\n",
            "\n",
            "\n",
            "----------------\n",
            "Reshape to single dimension (x.reshape(-1))\n",
            "\n",
            "tensor([51, 70, 80, 36, 32, 60, 87, 10, 16, 87, 52, 89,  3, 54, 18, 45, 79, 14,\n",
            "        18, 68, 64, 52, 62, 19, 29, 78, 88, 97, 89, 14, 57, 84, 43,  1, 53, 99,\n",
            "        69, 61, 81, 39, 54, 45,  8, 38,  6, 87, 67, 13, 43, 42, 63, 86, 25, 89,\n",
            "        51, 10, 67, 97, 23, 31]) torch.Size([60])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randint(0,100,size=(3,4,5))\n",
        "print('Orginal tensor shape: ', x.shape)\n",
        "print('Orginal tensor: ')\n",
        "print(x)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Shape to have 12 rows and 5 columns (x.reshape((12,5))): \\n')\n",
        "print(x.reshape((12,5)), x.reshape((12,5)).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Shape to have 10 rows and using -1 to infer based on the elements in other dimensions (x.reshape(10,-1)): \\n')\n",
        "print(x.reshape(10,-1), x.reshape(10,-1).shape) # Can use -1 to specify one of the dimensions which is automatically inferred based on the elements in other dimensions\n",
        "print(\"----------------\")\n",
        "print('\\n')\n",
        "print('Reshape to have 4 rows and 3 columns (x.reshape(5,4,3)): \\n')\n",
        "print(x.reshape(5,4,3), x.reshape(5,4,3).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Reshape to single dimension (x.reshape(-1))\\n')\n",
        "print(x.reshape(-1), x.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnORYt7VyVNz"
      },
      "source": [
        "## Get the value as a Python number from a one element tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzaKj9r0yXN0",
        "outputId": "0d52d8b9-3b86-49f1-e0c0-652214e40f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0499])\n",
            "-0.049882568418979645\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7sb67gbuGR2"
      },
      "source": [
        "## Multidimensional tensors can be changed to singe dimension with Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn-tVIG8uFp5",
        "outputId": "80dc42a2-5a80-447e-dd88-fcfd5559dbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[16, 13, 10,  9, 18],\n",
            "         [ 5,  9,  2,  7, 12],\n",
            "         [18,  3, 11, 17, 18],\n",
            "         [12, 11,  4,  9, 14]],\n",
            "\n",
            "        [[ 2, 14, 15,  4, 17],\n",
            "         [10, 11, 19,  1, 14],\n",
            "         [ 5, 15, 15,  4,  4],\n",
            "         [19,  6, 10, 14,  7]],\n",
            "\n",
            "        [[18, 12, 15, 16,  0],\n",
            "         [ 8,  2,  2,  1, 17],\n",
            "         [ 9,  5, 12, 17, 17],\n",
            "         [ 4, 19, 18,  1, 19]]])\n",
            "torch.Size([3, 4, 5])\n",
            "tensor([16, 13, 10,  9, 18,  5,  9,  2,  7, 12, 18,  3, 11, 17, 18, 12, 11,  4,\n",
            "         9, 14,  2, 14, 15,  4, 17, 10, 11, 19,  1, 14,  5, 15, 15,  4,  4, 19,\n",
            "         6, 10, 14,  7, 18, 12, 15, 16,  0,  8,  2,  2,  1, 17,  9,  5, 12, 17,\n",
            "        17,  4, 19, 18,  1, 19])\n",
            "torch.Size([60])\n"
          ]
        }
      ],
      "source": [
        "#x = torch.rand(size=(3,4,5)) # 3D tensor\n",
        "x = torch.randint(0,20,size=(3,4,5))  # 3D tensor\n",
        "print(x)\n",
        "print(x.shape)               # 3x4x5\n",
        "print(x.flatten())\n",
        "print(x.flatten().shape)     # 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBSAnT-suf3Y"
      },
      "source": [
        "##Dimensions can be added or removed with squeeze and unsqueeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km6mtJCL099t"
      },
      "source": [
        "   ### Add dimension with unsequeeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S0fVtyuucwO",
        "outputId": "f33b0976-a988-4b6b-9d99-501b0b8e192e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 3, 14, 14, 10,  4],\n",
            "          [11,  7,  1,  5, 12],\n",
            "          [16, 16,  4, 14,  3],\n",
            "          [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "         [[14, 16,  1,  9, 12],\n",
            "          [15,  0, 19,  1,  2],\n",
            "          [17, 14,  3, 13,  2],\n",
            "          [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "         [[ 4, 11,  6, 10,  3],\n",
            "          [ 3,  5,  8,  0,  7],\n",
            "          [ 3,  4, 19, 19, 12],\n",
            "          [ 2, 12,  9,  9,  1]]]])\n",
            "\n",
            "\n",
            "Original tensor shape torch.Size([3, 4, 5])\n",
            "Unsequeeze along axis 0 (xs=x.unsqueeze(dim=0)) torch.Size([1, 3, 4, 5])\n",
            "\n",
            "\n",
            "tensor([[[[[ 3, 14, 14, 10,  4],\n",
            "           [11,  7,  1,  5, 12],\n",
            "           [16, 16,  4, 14,  3],\n",
            "           [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "          [[14, 16,  1,  9, 12],\n",
            "           [15,  0, 19,  1,  2],\n",
            "           [17, 14,  3, 13,  2],\n",
            "           [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "          [[ 4, 11,  6, 10,  3],\n",
            "           [ 3,  5,  8,  0,  7],\n",
            "           [ 3,  4, 19, 19, 12],\n",
            "           [ 2, 12,  9,  9,  1]]]]])\n",
            "Unsequeeze along axis 0 a second time (xs.unsqueeze(0).shape): torch.Size([1, 1, 3, 4, 5])\n",
            "\n",
            "\n",
            "---------\n",
            "\n",
            "\n",
            "\n",
            "Original tensor\n",
            "\n",
            "tensor([[[ 3, 14, 14, 10,  4],\n",
            "         [11,  7,  1,  5, 12],\n",
            "         [16, 16,  4, 14,  3],\n",
            "         [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "        [[14, 16,  1,  9, 12],\n",
            "         [15,  0, 19,  1,  2],\n",
            "         [17, 14,  3, 13,  2],\n",
            "         [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "        [[ 4, 11,  6, 10,  3],\n",
            "         [ 3,  5,  8,  0,  7],\n",
            "         [ 3,  4, 19, 19, 12],\n",
            "         [ 2, 12,  9,  9,  1]]])\n",
            "Unsequeeze along axis 1 (x.unsqueeze(1)) :  torch.Size([3, 1, 4, 5])\n",
            "tensor([[[[ 3, 14, 14, 10,  4],\n",
            "          [11,  7,  1,  5, 12],\n",
            "          [16, 16,  4, 14,  3],\n",
            "          [ 5,  5,  5, 11,  5]]],\n",
            "\n",
            "\n",
            "        [[[14, 16,  1,  9, 12],\n",
            "          [15,  0, 19,  1,  2],\n",
            "          [17, 14,  3, 13,  2],\n",
            "          [ 1, 13, 18, 13, 18]]],\n",
            "\n",
            "\n",
            "        [[[ 4, 11,  6, 10,  3],\n",
            "          [ 3,  5,  8,  0,  7],\n",
            "          [ 3,  4, 19, 19, 12],\n",
            "          [ 2, 12,  9,  9,  1]]]])\n",
            "\n",
            "\n",
            "torch.Size([3, 4, 1, 5])\n",
            "Unsequeeze along axis 2 (x.unsqueeze(2)) :  torch.Size([3, 4, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "#x = torch.rand(size=(3,4,5))\n",
        "x = torch.randint(0,20,size=(3,4,5))\n",
        "xs = x.unsqueeze(dim=0)   # unsequeeze along axis 0\n",
        "xs2 = x.unsqueeze(1)  # unsequeeze along axis 1\n",
        "\n",
        "print(xs) # A new dimension is added while all the following dimension are incremented by 1 ( positionally)\n",
        "print('\\n')\n",
        "print('Original tensor shape',x.shape)\n",
        "print('Unsequeeze along axis 0 (xs=x.unsqueeze(dim=0))',xs.shape)\n",
        "print('\\n')\n",
        "\n",
        "print(xs.unsqueeze(0)) # Can apply this operation as many times as required\n",
        "print('Unsequeeze along axis 0 a second time (xs.unsqueeze(0).shape):',xs.unsqueeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"---------\\n\")\n",
        "print('\\n')\n",
        "print('Original tensor\\n')\n",
        "print(x)\n",
        "print('Unsequeeze along axis 1 (x.unsqueeze(1)) : ',xs2.shape)\n",
        "\n",
        "print(xs2) # Unsqueeze can also be applied to other intermediate dimensions\n",
        "print('\\n')\n",
        "xs3=x.unsqueeze(2)\n",
        "print(xs3.shape)\n",
        "print('Unsequeeze along axis 2 (x.unsqueeze(2)) : ',xs3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6MGPQ6Zxk2M"
      },
      "source": [
        "### Remove dimension with sequeeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfDx9SZBxfc-",
        "outputId": "8305dde2-6a7c-43a7-c737-6a72b1c3c70e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xs.shape :  torch.Size([1, 3, 4, 5])\n",
            "Original tensor xs\n",
            "\n",
            "tensor([[[[ 3, 14, 14, 10,  4],\n",
            "          [11,  7,  1,  5, 12],\n",
            "          [16, 16,  4, 14,  3],\n",
            "          [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "         [[14, 16,  1,  9, 12],\n",
            "          [15,  0, 19,  1,  2],\n",
            "          [17, 14,  3, 13,  2],\n",
            "          [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "         [[ 4, 11,  6, 10,  3],\n",
            "          [ 3,  5,  8,  0,  7],\n",
            "          [ 3,  4, 19, 19, 12],\n",
            "          [ 2, 12,  9,  9,  1]]]])\n",
            "sequeze axis 0 xs.squeeze(0)\n",
            "tensor([[[ 3, 14, 14, 10,  4],\n",
            "         [11,  7,  1,  5, 12],\n",
            "         [16, 16,  4, 14,  3],\n",
            "         [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "        [[14, 16,  1,  9, 12],\n",
            "         [15,  0, 19,  1,  2],\n",
            "         [17, 14,  3, 13,  2],\n",
            "         [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "        [[ 4, 11,  6, 10,  3],\n",
            "         [ 3,  5,  8,  0,  7],\n",
            "         [ 3,  4, 19, 19, 12],\n",
            "         [ 2, 12,  9,  9,  1]]])\n",
            "xs.squeeze(0).shape: torch.Size([3, 4, 5])\n",
            "\n",
            "\n",
            "-------------\n",
            "xs2.shape :  torch.Size([3, 1, 4, 5])\n",
            "Original tensor xs2\n",
            "\n",
            "tensor([[[[ 3, 14, 14, 10,  4],\n",
            "          [11,  7,  1,  5, 12],\n",
            "          [16, 16,  4, 14,  3],\n",
            "          [ 5,  5,  5, 11,  5]]],\n",
            "\n",
            "\n",
            "        [[[14, 16,  1,  9, 12],\n",
            "          [15,  0, 19,  1,  2],\n",
            "          [17, 14,  3, 13,  2],\n",
            "          [ 1, 13, 18, 13, 18]]],\n",
            "\n",
            "\n",
            "        [[[ 4, 11,  6, 10,  3],\n",
            "          [ 3,  5,  8,  0,  7],\n",
            "          [ 3,  4, 19, 19, 12],\n",
            "          [ 2, 12,  9,  9,  1]]]])\n",
            "sequeze axis 1 with xs2.squeeze(1)\n",
            "tensor([[[ 3, 14, 14, 10,  4],\n",
            "         [11,  7,  1,  5, 12],\n",
            "         [16, 16,  4, 14,  3],\n",
            "         [ 5,  5,  5, 11,  5]],\n",
            "\n",
            "        [[14, 16,  1,  9, 12],\n",
            "         [15,  0, 19,  1,  2],\n",
            "         [17, 14,  3, 13,  2],\n",
            "         [ 1, 13, 18, 13, 18]],\n",
            "\n",
            "        [[ 4, 11,  6, 10,  3],\n",
            "         [ 3,  5,  8,  0,  7],\n",
            "         [ 3,  4, 19, 19, 12],\n",
            "         [ 2, 12,  9,  9,  1]]])\n",
            "xs2.squeeze(1).shape: torch.Size([3, 4, 5])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"xs.shape : \",xs.shape)\n",
        "print('Original tensor xs\\n')\n",
        "print(xs)\n",
        "print(\"sequeze axis 0 xs.squeeze(0)\")\n",
        "print(xs.squeeze(0))\n",
        "print('xs.squeeze(0).shape:',xs.squeeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"-------------\")\n",
        "print(\"xs2.shape : \",xs2.shape)\n",
        "print('Original tensor xs2\\n')\n",
        "print(xs2)\n",
        "print(\"sequeze axis 1 with xs2.squeeze(1)\")\n",
        "print(xs2.squeeze(1))\n",
        "print('xs2.squeeze(1).shape:',xs2.squeeze(1).shape)\n",
        "print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCSFLA8F_MY4"
      },
      "source": [
        "## Combining Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKUUkpOq3tFg"
      },
      "source": [
        "### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC5MoIYd24r0",
        "outputId": "219d45cc-1f3d-48ed-8e95-59bd6403d742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x1:\n",
            " tensor([[[5, 5, 9, 9],\n",
            "         [2, 6, 4, 8],\n",
            "         [8, 7, 1, 6]],\n",
            "\n",
            "        [[0, 6, 8, 9],\n",
            "         [0, 3, 1, 6],\n",
            "         [2, 0, 2, 7]]]) \n",
            "\n",
            "x2:\n",
            " tensor([[[9, 3, 1, 7],\n",
            "         [2, 4, 1, 9],\n",
            "         [0, 1, 4, 9]],\n",
            "\n",
            "        [[7, 7, 0, 7],\n",
            "         [7, 6, 4, 6],\n",
            "         [2, 4, 2, 7]]]) \n",
            "\n",
            "CONCATENATING TENSORS\n",
            "\n",
            "Concatenating two tensors along axis 1 (torch.cat([x1,x2],dim=1))\n",
            "tensor([[[5, 5, 9, 9],\n",
            "         [2, 6, 4, 8],\n",
            "         [8, 7, 1, 6],\n",
            "         [9, 3, 1, 7],\n",
            "         [2, 4, 1, 9],\n",
            "         [0, 1, 4, 9]],\n",
            "\n",
            "        [[0, 6, 8, 9],\n",
            "         [0, 3, 1, 6],\n",
            "         [2, 0, 2, 7],\n",
            "         [7, 7, 0, 7],\n",
            "         [7, 6, 4, 6],\n",
            "         [2, 4, 2, 7]]])\n",
            "New Shape:  torch.Size([2, 6, 4])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.randint(0,10,size=(2,3,4))\n",
        "x2 = torch.randint(0,10,size=(2,3,4))\n",
        "\n",
        "print('x1:\\n', x1, \"\\n\")\n",
        "print('x2:\\n', x2, \"\\n\")\n",
        "\n",
        "print('CONCATENATING TENSORS\\n')\n",
        "\n",
        "print('Concatenating two tensors along axis 1 (torch.cat([x1,x2],dim=1))')\n",
        "print(torch.cat([x1,x2],dim=1))\n",
        "print('New Shape: ', torch.cat([x1,x2],dim=1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfllpE4D4Whb",
        "outputId": "bc280866-5ee2-4eda-f0b4-d89db9b7c727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Concatenating three tensors (x1,x2,x3) along axis 0\n",
            "\n",
            "x1 shape (2,3,4) : \n",
            " tensor([[[5, 5, 9, 9],\n",
            "         [2, 6, 4, 8],\n",
            "         [8, 7, 1, 6]],\n",
            "\n",
            "        [[0, 6, 8, 9],\n",
            "         [0, 3, 1, 6],\n",
            "         [2, 0, 2, 7]]]) \n",
            "\n",
            "x2 shape (2,3,4) : \n",
            " tensor([[[9, 3, 1, 7],\n",
            "         [2, 4, 1, 9],\n",
            "         [0, 1, 4, 9]],\n",
            "\n",
            "        [[7, 7, 0, 7],\n",
            "         [7, 6, 4, 6],\n",
            "         [2, 4, 2, 7]]]) \n",
            "\n",
            "x3 (size=(1,3,4)):\n",
            " tensor([[[5, 1, 6, 8],\n",
            "         [2, 2, 1, 5],\n",
            "         [1, 1, 7, 0]]]) \n",
            "\n",
            "Concatenate with torch.cat([x1,x2,x3],dim=0)\n",
            "tensor([[[5, 5, 9, 9],\n",
            "         [2, 6, 4, 8],\n",
            "         [8, 7, 1, 6]],\n",
            "\n",
            "        [[0, 6, 8, 9],\n",
            "         [0, 3, 1, 6],\n",
            "         [2, 0, 2, 7]],\n",
            "\n",
            "        [[9, 3, 1, 7],\n",
            "         [2, 4, 1, 9],\n",
            "         [0, 1, 4, 9]],\n",
            "\n",
            "        [[7, 7, 0, 7],\n",
            "         [7, 6, 4, 6],\n",
            "         [2, 4, 2, 7]],\n",
            "\n",
            "        [[5, 1, 6, 8],\n",
            "         [2, 2, 1, 5],\n",
            "         [1, 1, 7, 0]]])\n",
            "New Shape:  torch.Size([5, 3, 4])\n",
            "---------------------------\n",
            "\n",
            "Concatenating three tensors (x1,x2,x4) along axis 2\n",
            "\n",
            "x1 shape (2,3,4) : \n",
            " tensor([[[5, 5, 9, 9],\n",
            "         [2, 6, 4, 8],\n",
            "         [8, 7, 1, 6]],\n",
            "\n",
            "        [[0, 6, 8, 9],\n",
            "         [0, 3, 1, 6],\n",
            "         [2, 0, 2, 7]]]) \n",
            "\n",
            "x2 shape (2,3,4) : \n",
            " tensor([[[9, 3, 1, 7],\n",
            "         [2, 4, 1, 9],\n",
            "         [0, 1, 4, 9]],\n",
            "\n",
            "        [[7, 7, 0, 7],\n",
            "         [7, 6, 4, 6],\n",
            "         [2, 4, 2, 7]]]) \n",
            "\n",
            "x4 (size=(2,3,1)):\n",
            " tensor([[[7],\n",
            "         [7],\n",
            "         [3]],\n",
            "\n",
            "        [[5],\n",
            "         [2],\n",
            "         [4]]]) \n",
            "\n",
            "Concatenate with torch.cat([x1,x2,x4],dim=2)\n",
            "tensor([[[5, 5, 9, 9, 9, 3, 1, 7, 7],\n",
            "         [2, 6, 4, 8, 2, 4, 1, 9, 7],\n",
            "         [8, 7, 1, 6, 0, 1, 4, 9, 3]],\n",
            "\n",
            "        [[0, 6, 8, 9, 7, 7, 0, 7, 5],\n",
            "         [0, 3, 1, 6, 7, 6, 4, 6, 2],\n",
            "         [2, 0, 2, 7, 2, 4, 2, 7, 4]]])\n",
            "New Shape:  torch.Size([2, 3, 9])\n"
          ]
        }
      ],
      "source": [
        "# x1 shape (2,3,4)\n",
        "# x2 shape (2,3,4)\n",
        "\n",
        "x3 = torch.randint(0,10,size=(1,3,4))\n",
        "x4 = torch.randint(0,10,size=(2,3,1))\n",
        "print('\\nConcatenating three tensors (x1,x2,x3) along axis 0\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x3 (size=(1,3,4)):\\n', x3, \"\\n\")\n",
        "print('Concatenate with torch.cat([x1,x2,x3],dim=0)')\n",
        "print(torch.cat([x1,x2,x3],dim=0))\n",
        "print('New Shape: ', torch.cat([x1,x2,x3],dim=0).shape)\n",
        "print(\"---------------------------\")\n",
        "print('\\nConcatenating three tensors (x1,x2,x4) along axis 2\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x4 (size=(2,3,1)):\\n', x4, \"\\n\")\n",
        "\n",
        "print('Concatenate with torch.cat([x1,x2,x4],dim=2)')\n",
        "print(torch.cat([x1,x2,x4],dim=2))\n",
        "print('New Shape: ', torch.cat([x1,x2,x4],dim=2).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyo1lMzY6wBc"
      },
      "source": [
        "### Stacking (similar to a combination of unsqueeze and cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtNmg-aq6x7V",
        "outputId": "58b8f76a-e4fa-4027-f898-4eaa6e80a5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x1: \n",
            "\n",
            "torch.Size([3, 4])\n",
            "tensor([[1, 8, 4, 9],\n",
            "        [8, 2, 0, 8],\n",
            "        [9, 3, 7, 0]])\n",
            "\n",
            "\n",
            "x2: \n",
            "\n",
            "torch.Size([3, 4])\n",
            "tensor([[3, 6, 8, 6],\n",
            "        [0, 8, 8, 0],\n",
            "        [4, 2, 4, 8]])\n",
            "\n",
            "\n",
            "stack x1 and x2 at dim=0 : (3, 4) --> (1, 3, 4) --> (N, 3, 4) \n",
            "\n",
            "tensor([[[1, 8, 4, 9],\n",
            "         [8, 2, 0, 8],\n",
            "         [9, 3, 7, 0]],\n",
            "\n",
            "        [[3, 6, 8, 6],\n",
            "         [0, 8, 8, 0],\n",
            "         [4, 2, 4, 8]]])\n",
            "New Shape: torch.Size([2, 3, 4]) \n",
            "\n",
            "stack x1 and x2 at dim=1: (3, 4) --> (3, 1, 4) --> (3, N, 4) \n",
            "\n",
            "tensor([[[1, 8, 4, 9],\n",
            "         [3, 6, 8, 6]],\n",
            "\n",
            "        [[8, 2, 0, 8],\n",
            "         [0, 8, 8, 0]],\n",
            "\n",
            "        [[9, 3, 7, 0],\n",
            "         [4, 2, 4, 8]]])\n",
            "New Shape: torch.Size([3, 2, 4]) \n",
            "\n",
            "stack x1 and x2 at dim=2: (3, 4) --> (3, 4, 1) --> (3, 4, N) \n",
            "\n",
            "tensor([[[1, 3],\n",
            "         [8, 6],\n",
            "         [4, 8],\n",
            "         [9, 6]],\n",
            "\n",
            "        [[8, 0],\n",
            "         [2, 8],\n",
            "         [0, 8],\n",
            "         [8, 0]],\n",
            "\n",
            "        [[9, 4],\n",
            "         [3, 2],\n",
            "         [7, 4],\n",
            "         [0, 8]]])\n",
            "New Shape: torch.Size([3, 4, 2]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.randint(0,10,size=(3,4))\n",
        "x2 = torch.randint(0,10,size=(3,4))\n",
        "print('x1: \\n')\n",
        "print(x1.shape)\n",
        "print(x1)\n",
        "print('\\n')\n",
        "print('x2: \\n')\n",
        "print(x2.shape)\n",
        "print(x2)\n",
        "print('\\n')\n",
        "\n",
        "print('stack x1 and x2 at dim=0 : (3, 4) --> (1, 3, 4) --> (N, 3, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=0)) #(3, 4) --> (1, 3, 4) --> (N, 3, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=0).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=1: (3, 4) --> (3, 1, 4) --> (3, N, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=1)) #(3, 4) --> (3, 1, 4) --> (3, N, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=1).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=2: (3, 4) --> (3, 4, 1) --> (3, 4, N) \\n')\n",
        "print(torch.stack([x1,x2],dim=2)) #(3, 4) --> (3, 4, 1) --> (3, 4, N)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=2).shape, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUnnbb5Z8PkH"
      },
      "source": [
        "### Tensor Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5e2VEI8McX",
        "outputId": "94c24b19-633d-47c0-a616-47578613875d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[100, 100, 100, 100, 100, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100, 100, 100, 100, 100, 100, 100],\n",
            "        [100, 100, 100, 100, 100, 100, 100]])\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.tensor([[1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4]])\n",
        "\n",
        "pad_left   = 1\n",
        "pad_right  = 2\n",
        "pad_top    = 1\n",
        "pad_bottom = 2\n",
        "\n",
        "x_pad = F.pad(x, (pad_left,pad_right,pad_top,pad_bottom), mode = 'constant', value=100)\n",
        "print(x_pad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584dHoKDzOc9"
      },
      "source": [
        "For 100+ Tensor operations you can visit;\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pnBBTc087ys"
      },
      "source": [
        "---\n",
        "# **Vector/Matrix operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaNLuHKAjnB"
      },
      "source": [
        "##Vector-Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma9WeU4lA0Hr",
        "outputId": "b28cd776-d20b-4799-da9c-64b2091a7deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3])\n",
            "tensor([ 1.1319,  1.8897, -0.3477]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([3])\n",
            "tensor([-0.6121, -1.1688,  0.9362]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([])\n",
            "tensor(-3.2270)\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([])\n",
            "tensor(-3.2270) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3)\n",
        "tensor2 = torch.randn(3)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yblHh9F7AyPj"
      },
      "source": [
        "##Vector-Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPo38Ku3ByfO",
        "outputId": "9df70caf-97c7-44d6-c65e-a97fbe30fd72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3, 4])\n",
            "tensor([[ 0.9891,  0.9550, -0.0259,  1.8527],\n",
            "        [ 1.2553,  2.0246,  1.0859,  0.8375],\n",
            "        [ 0.1375,  0.3019,  0.5415,  1.1993]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([4])\n",
            "tensor([-1.2244, -0.3910,  0.4502,  0.3181]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([3])\n",
            "tensor([-1.0068, -1.5733,  0.3389])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([3])\n",
            "tensor([-1.0068, -1.5733,  0.3389]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaGupG3FB-Io"
      },
      "source": [
        "##Matrix-Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUlBUKs5CHw4",
        "outputId": "e8995d7c-cffa-4548-9fbe-9ce9551cf84f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3, 4])\n",
            "tensor([[ 0.8742,  0.7288, -0.7915,  0.5332],\n",
            "        [ 0.1927, -0.3815, -1.1066, -1.1460],\n",
            "        [-0.7005, -1.6357,  0.6566, -2.0769]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([4, 5])\n",
            "tensor([[ 1.6707, -0.3872, -1.2831, -0.7333, -0.6577],\n",
            "        [-0.4552, -1.5502,  0.0746,  1.2933, -0.3359],\n",
            "        [ 0.5701,  0.2632,  1.3424, -0.2436,  2.4322],\n",
            "        [-1.0749, -0.7285,  1.7016, -0.7938,  2.1063]]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([3, 5])\n",
            "tensor([[ 0.1042, -2.0651, -1.2225,  0.0711, -1.6218],\n",
            "        [ 1.0966,  1.0605, -3.7112,  0.5446, -5.1038],\n",
            "        [ 2.1811,  4.4926, -1.8759, -0.1129, -1.7677]])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([3, 5])\n",
            "tensor([[ 0.1042, -2.0651, -1.2225,  0.0711, -1.6218],\n",
            "        [ 1.0966,  1.0605, -3.7112,  0.5446, -5.1038],\n",
            "        [ 2.1811,  4.4926, -1.8759, -0.1129, -1.7677]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS248-PNCer2",
        "outputId": "c624f97b-98f1-43dc-8f39-51cd9d287a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([2, 3, 4])\n",
            "tensor([[[ 0.1660, -0.4447, -0.5241,  1.0165],\n",
            "         [ 0.8900,  0.4053,  1.6261,  0.7469],\n",
            "         [-0.6327,  0.5627,  0.4088, -0.3258]],\n",
            "\n",
            "        [[-1.7098, -0.7971,  0.9406,  0.7309],\n",
            "         [-0.0399,  0.0482, -1.9160, -1.7570],\n",
            "         [ 1.2088, -1.5576,  0.3302,  1.1911]]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([2, 4, 5])\n",
            "tensor([[[-1.8116, -1.8630,  0.5306, -1.1185,  0.4121],\n",
            "         [ 2.3589,  1.8304,  0.6648, -1.5546,  1.4902],\n",
            "         [-0.9655,  1.0674, -0.9448,  0.1249, -1.0627],\n",
            "         [-0.2957,  0.3560,  0.2481, -0.0909,  1.0653]],\n",
            "\n",
            "        [[ 0.8747,  0.7209, -0.3043,  0.0740, -0.0213],\n",
            "         [-0.1245, -1.0682, -1.0355, -0.1836,  1.4178],\n",
            "         [ 0.8228,  0.0829,  1.0561,  1.3416,  0.0135],\n",
            "         [ 0.9490, -0.8745, -0.5836, -1.1490, -1.5975]]]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[-1.1442, -1.3206,  0.5398,  0.3478,  1.0456],\n",
            "         [-2.4472,  1.0855, -0.6094, -1.4904,  0.0384],\n",
            "         [ 2.1749,  2.5289, -0.4287, -0.0865, -0.2038]],\n",
            "\n",
            "        [[ 0.0713, -0.9425,  1.9125,  0.4417, -2.2486],\n",
            "         [-3.2848,  1.2976, -1.0359, -0.5635,  2.8500],\n",
            "         [ 2.6532,  1.5210,  0.8986, -0.5502, -4.1323]]])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[-1.1442, -1.3206,  0.5398,  0.3478,  1.0456],\n",
            "         [-2.4472,  1.0855, -0.6094, -1.4904,  0.0384],\n",
            "         [ 2.1749,  2.5289, -0.4287, -0.0865, -0.2038]],\n",
            "\n",
            "        [[ 0.0713, -0.9425,  1.9125,  0.4417, -2.2486],\n",
            "         [-3.2848,  1.2976, -1.0359, -0.5635,  2.8500],\n",
            "         [ 2.6532,  1.5210,  0.8986, -0.5502, -4.1323]]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(2, 3, 4)\n",
        "tensor2 = torch.randn(2, 4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-D5VGEzkG2"
      },
      "source": [
        "---\n",
        "# **Converting a Torch tensor to a NumPy array, and vice versa**\n",
        "\n",
        "Torch tensors and numpy arrays can be converted to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgdtmEgE0GH-",
        "outputId": "44627bb7-d2a6-4d16-96cc-371993078967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "#tensor to numpy\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "y = x.numpy()\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8hKRHxs1h_e",
        "outputId": "2e20bf2c-45d4-46c6-81b6-6e1006e54020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#numpy to tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skX8vcFY1CvO"
      },
      "source": [
        "If underlying memory locations is on CPU, changing one will change the other;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9t5ed_1OHT",
        "outputId": "bc49c2dd-4054-4183-c8d8-2c3104a333cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az4LUKuV1fvU",
        "outputId": "8bd79939-7e9c-4bb5-dbfa-9744a401d47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0T8AGbH12F-"
      },
      "source": [
        "---\n",
        "# **CUDA Tensors**\n",
        "\n",
        "Tensors can be moved onto any device using the `.to` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzWeMu4d2DKQ",
        "outputId": "7206d999-5368-43da-9e53-7ef1b077a4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3., 3.], device='cuda:0')\n",
            "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# run this cell only if CUDA is available\n",
        "# Use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SvvIGUYeN3"
      },
      "source": [
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCWblVgRAo6F"
      },
      "source": [
        "---\n",
        "# **`Autograd` Package**\n",
        "\n",
        "\n",
        "\n",
        "* Provides automatic differentiation for all operations on Tensors\n",
        "* A define-by-run framework (backprop is defined by how the code is run, and that every single iteration can be different)\n",
        "* If the attribute `.requires_grad`  of a tensor is set to as `True`, all opeations on the tensor will be tracked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CR2vt1lC6ee",
        "outputId": "422a0780-87b8-4d6e-aea5-e426a0cf7132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrmO-TZyDspo",
        "outputId": "585f9506-995b-4899-8940-bee47623a624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x310107e80>\n"
          ]
        }
      ],
      "source": [
        "#y was created as a result of an operation, so it has a grad_fn.\n",
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8uCi4ONDwjl",
        "outputId": "b40d1814-633e-4ba8-a7bc-b191c88c8157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIhuuDoxDoka",
        "outputId": "ec7adb1d-3ac6-4d3e-9c9b-b28c8d66d976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x312512590>\n"
          ]
        }
      ],
      "source": [
        "#change an existing tensorâ€™s requires_grad flag in-place\n",
        "\n",
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z05jRG-2DR12"
      },
      "source": [
        "* When the computation is finished, `.backward()` can be calle to compute all the gradients automatically (gadient will be accumulated into `.grad` attribute)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFM6_oJfEUej",
        "outputId": "4d177aa2-9c29-4391-fa82-428cc192ae45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "out.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGkAOH1YESUV"
      },
      "source": [
        "* You can also stop autograd from tracking history by wrapping the code block in with torch.no_grad():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLLP63igFIhG",
        "outputId": "c5b52001-75c8-41bc-fa75-41651efce063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1M_lELkFo6l"
      },
      "source": [
        "* For more infomation: https://pytorch.org/docs/stable/autograd.html#function\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHlkLJNCF0LJ"
      },
      "source": [
        "---\n",
        "# **Neural Networks (NN)**\n",
        "\n",
        "* NN can be construted with `torch.nn` package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OSYPwdhtGc1o"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfJ_jUwRQ_qo"
      },
      "source": [
        "* nn depends on autograd to define models and differentiate them.\n",
        "* A typical training procedure for a neural network is as follows:\n",
        "\n",
        "    **i.** Define the neural network that has some learnable parameters (or weights).\n",
        "    \n",
        "    > The learnable parameters of a model are returned by net.parameters()\n",
        "\n",
        "  **ii.** Iterate over a dataset of inputs\n",
        "\n",
        "    **iii.** Process input through the network\n",
        "\n",
        "    **iv.** Compute the loss (how far is the output from being correct).\n",
        "\n",
        "    **v.** Propagate gradients back into the networkâ€™s parameters with loss.backward()\n",
        "\n",
        "    **vi.** Update the weights of the network.\n",
        "\n",
        "    > This can be performed by any of the various different update rules that are implemented in `torch.optim` package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttXXwJEqQNu3",
        "outputId": "13c20c91-733f-44f1-90d6-4e37722c248b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1000]) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "#CREATE INPUT, AND OUTPUT\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "print(x.size(), y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ro9m4BQlTW",
        "outputId": "d9c25c8d-ded3-4274-eecd-1b5d9fce65b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#DEFINE NN:\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    #ReLU: rectified linear unit, activation function\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5eLJut3RT4_",
        "outputId": "ba748abd-d726-43a7-b79e-c1fa11e7351e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of learnable parameters:  4\n",
            "Size of the first parameter:  torch.Size([100, 1000])\n"
          ]
        }
      ],
      "source": [
        "#LEARNABLE PARAMETERS IN THE MODEL:\n",
        "params = list(model.parameters())\n",
        "print(\"Length of learnable parameters: \",len(params))\n",
        "print(\"Size of the first parameter: \", params[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4RmEFGaTEz-",
        "outputId": "41baf2e6-c638-4326-bef9-228254fd80d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function: MSELoss()\n"
          ]
        }
      ],
      "source": [
        "# WE WILL NEED A LOSS FUNCTION FOR STEP iv.\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "print(\"Loss function:\", loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLNQlNlbKNzl",
        "outputId": "1924cf21-d0b5-4471-a155-a6637f6044ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer:  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TO UPDATE WEIGHTS, LETS USE ADAM\n",
        "# THAT IS ALREAY IMPLEMENTED IN torch.optim\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Optimizer: \", optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIWsyb0zVzX3",
        "outputId": "2414532c-9ead-471f-9644-4fa394f9bef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99 2.2021669210392503e-10\n",
            "199 3.12144025904626e-11\n",
            "299 1.2418375355816025e-11\n",
            "399 8.005280466294451e-12\n",
            "499 5.829103692789328e-12\n"
          ]
        }
      ],
      "source": [
        " #TRAINING LOOP:\n",
        "for t in range(500):\n",
        "\n",
        "    # Forward pass:\n",
        "    # Feed input to the model\n",
        "    # and compute predicted.\n",
        "\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    #with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "\n",
        "\n",
        "    # and update the weights.\n",
        "\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwTP0YKMQ3pS"
      },
      "source": [
        "---\n",
        "# **Training an image classifier**\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
        "2. Define a Convolutional Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x_sKrxzRMTf"
      },
      "source": [
        "**1. Loading and normalizing CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJbcmsfRx-Ks",
        "outputId": "0ef07c29-e7e2-4489-96f7-aaf99308c3ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aryansharanreddyguda/miniconda3/envs/nndl/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
            "  entry = pickle.load(f, encoding=\"latin1\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "########################################################################\n",
        "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1].\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-SVwefYRhBb"
      },
      "source": [
        "Let us show some of the training images, for fun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "68BrNCxURajK",
        "outputId": "d66644c8-b166-467c-ba07-f41b19c954ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  cat   dog horse horse\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVwlDD03RvqN"
      },
      "source": [
        "**2. Define a Convolutional Neural Network**\n",
        "\n",
        "CNNs systematically apply learned filters to input images in order to\n",
        "create feature maps that summarize the presence of those features in the input.\n",
        "\n",
        "We will use Conv2d for convolution layers. It applies a 2D convolution over an input signal composed of several input planes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIcwpZBJVfyn"
      },
      "source": [
        "Conv2D input :\n",
        "\n",
        "N is the batch size, C is the number of channels, H is the height of input planes and W is width\n",
        "\n",
        "$(N,C_{in},H_{in},W_{in})$ or  $(C_{in},H_{in},W_{in})$\n",
        "\n",
        "Conv2D output:\n",
        "\n",
        "$H_{out} = \\frac{H_{in} + 2 * padding[0] - dilation[0]*(kernel_{-}size[0]-1)-1}{stride[0]} +1$\n",
        "\n",
        "$W_{out} = \\frac{W_{in} + 2 * padding[1] - dilation[1]*(kernel_{-}size[1]-1)-1}{stride[1]} +1$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiOITK9ovvn0",
        "outputId": "fcc551bd-75d9-4318-f494-7e0bf3514bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#if we use equation given above\n",
        "#input size:   32x32x3\n",
        "#After conv1   28x28x6\n",
        "#After pooling 14x14x6\n",
        "#After conv2   10x10x16\n",
        "#After pooling 5x5x16\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #takes 3-channel images, 6 output channels, 5x5 square convolution kernel\n",
        "        #initialize 6 5x5-kernels, each having a total of 3 channels\n",
        "        #color images of 32x32 pixels in size\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        #A limitation of the feature map output of convolutional\n",
        "        #layers is that they record the precise position of features\n",
        "        #in the input. This means that small movements in the\n",
        "        #position of the feature in the input image will result in a\n",
        "        #different feature map.This can happen with re-cropping, rotation,\n",
        "        #shifting, and other minor changes to the input image.\n",
        "        #A common approach to addressing this problem from signal\n",
        "        #processing is called down sampling. This is where a lower\n",
        "        #resolution version of an input signal is created that still\n",
        "        #contains the large or important structural elements.\n",
        "        #A more robust and common approach is to use a POOLING LAYER.\n",
        "        #A pooling layer is a new layer added\n",
        "        #after the convolutional layer.\n",
        "        #The pooling layer operates upon each feature map separately\n",
        "        #to create a new set of the same number of pooled feature maps.\n",
        "        #The size of the pooling operation or filter is smaller than the\n",
        "        #size of the feature map\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_A9GyQHaDOU"
      },
      "source": [
        "**3. Define a Loss function and optimizer**\n",
        "\n",
        "Letâ€™s use a Classification Cross-Entropy loss and  stochastic gradient descent (SGD) with momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9-bJcL9mMEN6"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI6WLMBeaX1q"
      },
      "source": [
        "**4. Train the network**\n",
        "\n",
        "We will loop over our data iterator, and feed the inputs to the network and optimize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpcFrIE8OBKF",
        "outputId": "e5a9ab97-bc7c-4b45-abc6-46e4eac96eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.191\n",
            "[1,  4000] loss: 1.900\n",
            "[1,  6000] loss: 1.702\n",
            "[1,  8000] loss: 1.592\n",
            "[1, 10000] loss: 1.512\n",
            "[1, 12000] loss: 1.465\n",
            "[2,  2000] loss: 1.395\n",
            "[2,  4000] loss: 1.375\n",
            "[2,  6000] loss: 1.333\n",
            "[2,  8000] loss: 1.298\n",
            "[2, 10000] loss: 1.306\n",
            "[2, 12000] loss: 1.251\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_lXZ-CawcU"
      },
      "source": [
        "**5. Test the network on the test data**\n",
        "\n",
        "We need to check if the network has learnt anything at all.\n",
        "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "First,  let us display an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yOFPvWQ-M7Ng",
        "outputId": "b0f15705-5537-4054-de98-d24887f3611c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12jmH6zbXKg"
      },
      "source": [
        "Now let us see what the neural network thinks these examples above are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "achD24npNJs3",
        "outputId": "de734c86-9462-48f8-bb86-73daa5f9a31b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted:    cat  ship  ship plane\n"
          ]
        }
      ],
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJEccRoEb5tX"
      },
      "source": [
        "The results seem pretty good. Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5c8qpdWbv7i",
        "outputId": "5c91d751-8369-4ced-d623-789a182fdf93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 55 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nndl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
