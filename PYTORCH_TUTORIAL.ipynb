{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHnQTYUwoh3l"
      },
      "source": [
        "# **What is Pytorch?**\n",
        "\n",
        "Pytorch is a python-based scientific computing package targeted for\n",
        "\n",
        "1.   replacement for NumPy to use the power of GPUs\n",
        "2.   deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **What is a Tensor?**\n",
        "\n",
        "Similar to NumPyâ€™s ndarrays, but can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_FbK8f7pWPJ",
        "outputId": "9254c39f-9b14-4140-98c6-52e40ea18cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6148, 0.1142, 0.3236],\n",
            "        [0.7092, 0.0686, 0.3135],\n",
            "        [0.0539, 0.2223, 0.5768],\n",
            "        [0.0419, 0.9949, 0.3076],\n",
            "        [0.7353, 0.3718, 0.8631]])\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9v4GRlApmWP"
      },
      "source": [
        "A tensor can have different datatypes;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbAFbE7p23C",
        "outputId": "6e6cab7c-e040-4f9b-c1d4-be46cdd9c845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "x datatype: torch.int64\n",
            "x:  tensor([[0, 0, 0]])\n",
            "\n",
            "y datatype: torch.float32\n",
            "y:  tensor([[0., 0., 0.]])\n",
            "\n",
            "z datatype: torch.float64\n",
            "z:  tensor([[0., 0., 0.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(1, 3, dtype=torch.long)\n",
        "print(\"\\nx datatype:\",x.dtype)\n",
        "print(\"x: \", x)\n",
        "\n",
        "y = torch.zeros(1, 3, dtype=torch.float)\n",
        "print(\"\\ny datatype:\", y.dtype)\n",
        "print(\"y: \", y)\n",
        "\n",
        "z = torch.zeros(1, 3, dtype=torch.double)\n",
        "print(\"\\nz datatype:\",z.dtype)\n",
        "print(\"z: \", z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htdXJDfmrW7z"
      },
      "source": [
        "A tensor can be constructed\n",
        "1. directly from data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG2VP9mIrXva",
        "outputId": "9442c572-60c7-455b-a702-8dc5bf7eb288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_moo-Ur0CF"
      },
      "source": [
        "2. based on an existing tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXK9xWXqr_bk",
        "outputId": "d464bd27-6567-4761-a8b9-e3c14c52320e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 0.0582, -1.8451, -0.1381],\n",
            "        [ 0.1094, -1.6179, -1.2470]], dtype=torch.float64)\n",
            "tensor([[ 1.6799,  0.0486, -0.1699],\n",
            "        [ 0.6132,  0.1152,  0.0673]])\n",
            "\n",
            "Size of the tensors:\n",
            " torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "y = torch.randn_like(x)                       #result will have the same size\n",
        "print(y)\n",
        "\n",
        "z = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
        "print(z)\n",
        "\n",
        "#get sizes of tensors;\n",
        "\n",
        "print(\"\\nSize of the tensors:\\n\",x.size(), y.size(), z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff_W4iyarZnH"
      },
      "source": [
        "Tensor indexing is similar to numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2c5ozMprdw7",
        "outputId": "2f01f5b1-608f-48db-cd1f-30d723610b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tensor x:\n",
            "tensor([[[6, 9, 6, 5, 8],\n",
            "         [1, 2, 5, 9, 8],\n",
            "         [5, 8, 2, 3, 7],\n",
            "         [0, 5, 7, 8, 8]],\n",
            "\n",
            "        [[5, 4, 4, 9, 7],\n",
            "         [0, 1, 8, 6, 6],\n",
            "         [5, 0, 0, 1, 9],\n",
            "         [7, 2, 0, 1, 2]],\n",
            "\n",
            "        [[3, 5, 6, 5, 6],\n",
            "         [5, 0, 2, 7, 1],\n",
            "         [6, 2, 3, 7, 2],\n",
            "         [4, 2, 7, 4, 5]]])\n",
            "\n",
            "\n",
            "x[0][0][0]\n",
            " tensor(6)\n",
            "x[1,2,3]\n",
            " tensor(1)\n",
            "x[-1,-1][2]\n",
            " tensor(7)\n",
            "x[-1,-1][-1]\n",
            " tensor(5)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Basic\n",
        "x = torch.randint(0,10,size=(3,4,5)) # 3D tensor\n",
        "\n",
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "# Some valid ways of accessing individual elements in the tensor\n",
        "print('x[0][0][0]\\n', x[0][0][0])\n",
        "print('x[1,2,3]\\n', x[1,2,3])\n",
        "print('x[-1,-1][2]\\n', x[-1,-1][2])\n",
        "print('x[-1,-1][-1]\\n', x[-1,-1][-1])\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZXfkOBsO1c"
      },
      "source": [
        "Tensors can be sliced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQNSOtIqsRtE",
        "outputId": "0467a3a1-6a61-43a2-b9d9-a4408ff048de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tensor x:\n",
            "tensor([[[6, 9, 6, 5, 8],\n",
            "         [1, 2, 5, 9, 8],\n",
            "         [5, 8, 2, 3, 7],\n",
            "         [0, 5, 7, 8, 8]],\n",
            "\n",
            "        [[5, 4, 4, 9, 7],\n",
            "         [0, 1, 8, 6, 6],\n",
            "         [5, 0, 0, 1, 9],\n",
            "         [7, 2, 0, 1, 2]],\n",
            "\n",
            "        [[3, 5, 6, 5, 6],\n",
            "         [5, 0, 2, 7, 1],\n",
            "         [6, 2, 3, 7, 2],\n",
            "         [4, 2, 7, 4, 5]]])\n",
            "\n",
            "\n",
            "x[0] (first dim.) \n",
            " torch.Size([4, 5]) \n",
            " tensor([[6, 9, 6, 5, 8],\n",
            "        [1, 2, 5, 9, 8],\n",
            "        [5, 8, 2, 3, 7],\n",
            "        [0, 5, 7, 8, 8]])\n",
            "x[:1] (first dim.) \n",
            " torch.Size([1, 4, 5]) \n",
            " tensor([[[6, 9, 6, 5, 8],\n",
            "         [1, 2, 5, 9, 8],\n",
            "         [5, 8, 2, 3, 7],\n",
            "         [0, 5, 7, 8, 8]]])\n",
            "x[:,1] (all dim. row=1) \n",
            " tensor([[1, 2, 5, 9, 8],\n",
            "        [0, 1, 8, 6, 6],\n",
            "        [5, 0, 2, 7, 1]])\n",
            "x[:,:,3] (all dim. all rows but only 3rd column) \n",
            " torch.Size([3, 4]) \n",
            " tensor([[5, 9, 3, 8],\n",
            "        [9, 6, 1, 1],\n",
            "        [5, 7, 7, 4]])\n",
            "x[:,:,-2:] (all dim., all rows but last 2 columns) \n",
            " torch.Size([3, 4, 2]) \n",
            " tensor([[[5, 8],\n",
            "         [9, 8],\n",
            "         [3, 7],\n",
            "         [8, 8]],\n",
            "\n",
            "        [[9, 7],\n",
            "         [6, 6],\n",
            "         [1, 9],\n",
            "         [1, 2]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 1],\n",
            "         [7, 2],\n",
            "         [4, 5]]])\n"
          ]
        }
      ],
      "source": [
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "print('x[0] (first dim.) \\n', x[0].shape,'\\n',x[0])\n",
        "print('x[:1] (first dim.) \\n', x[:1].shape,'\\n',x[:1])\n",
        "print('x[:,1] (all dim. row=1) \\n', x[:,1])\n",
        "print('x[:,:,3] (all dim. all rows but only 3rd column) \\n', x[:,:,3].shape,'\\n',x[:,:,3])\n",
        "print('x[:,:,-2:] (all dim., all rows but last 2 columns) \\n',x[:,:,-2:].shape,'\\n', x[:,:,-2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vODYPzjYvAyb"
      },
      "source": [
        "---\n",
        "# **Tensor Operations:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b_RDkeU-Qf6"
      },
      "source": [
        "##Operations can be performed with different syntaxes. For addition;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3lJAJDvSVc",
        "outputId": "2156c615-ea12-458d-bdea-13835577f4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1602,  0.7772, -0.6161],\n",
            "        [-0.1923,  0.3087,  1.6602]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 1:\n",
        "x = torch.rand(2, 3)\n",
        "y = torch.randn_like(x)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBFY3Bdvvhbz",
        "outputId": "6f55e075-1ea8-4333-d032-1933ed0bdffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1602,  0.7772, -0.6161],\n",
            "        [-0.1923,  0.3087,  1.6602]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 2:\n",
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcAIOqwYv7W_",
        "outputId": "44afcd97-1d1d-4417-e1ac-87a09323a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1824,  1.0786,  0.9681],\n",
            "        [-0.3787,  0.8496, -0.6554]])\n",
            "tensor([[-0.2534,  1.1913,  1.1565],\n",
            "        [ 0.1838,  1.7172,  0.2472]])\n"
          ]
        }
      ],
      "source": [
        "#syntax 4: in-place, post-fixed with an _\n",
        "print(y)\n",
        "\n",
        "y.add_(x)\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZPa1sZvrSN",
        "outputId": "e5781dab-c7fd-4e1f-e980-ec6c7c07bdeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1602,  0.7772, -0.6161],\n",
              "        [-0.1923,  0.3087,  1.6602]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#syntax 3: an output tensor as argument\n",
        "result = torch.empty(2, 3)\n",
        "print(result)\n",
        "torch.add(x, y, out=result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-grS8Y8M9QJp"
      },
      "source": [
        "##Reduction operations (sum(), mean(), std(), max(), argmax(), prod(), unique() etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YD5yiV59SYh",
        "outputId": "d73a6b5b-ba2b-4e7e-c56d-4b0282ea5124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "original x1:\n",
            "tensor([1., 1., 1.])\n",
            "\n",
            "original x2:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "x1.sum()\n",
            "tensor(3.)\n",
            "tensor(3.)\n",
            "\n",
            "x2.sum()\n",
            "tensor(12.)\n",
            "tensor(12.)\n",
            "\n",
            "x2.sum(axis=0)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "\n",
            "x2.sum(axis=1)\n",
            "tensor([4., 4., 4.])\n",
            "tensor([4., 4., 4.])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.ones(3)\n",
        "x2 = torch.ones(size=(3,4))\n",
        "\n",
        "print('\\noriginal x1:')\n",
        "print(x1)\n",
        "\n",
        "print('\\noriginal x2:')\n",
        "print(x2)\n",
        "\n",
        "print('\\nx1.sum()')\n",
        "print(x1.sum())\n",
        "print(torch.sum(x1))\n",
        "\n",
        "print('\\nx2.sum()')\n",
        "print(x2.sum())\n",
        "print(torch.sum(x2))\n",
        "\n",
        "print('\\nx2.sum(axis=0)')\n",
        "print(x2.sum(axis=0))\n",
        "print(torch.sum(x2, axis=0))\n",
        "\n",
        "print('\\nx2.sum(axis=1)')\n",
        "print(x2.sum(axis=1))\n",
        "print(torch.sum(x2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzc332nH9pjl"
      },
      "source": [
        "---\n",
        "# **Handling Tensors:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMXNsgRbxbWg"
      },
      "source": [
        "## Resize/reshape a tensor with `torch.view` and `torch.reshape`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QF0sEQ03KuV"
      },
      "source": [
        "### torch.view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rrCRqC7xx-R",
        "outputId": "575c1535-b158-476a-9e43-7a25bf17bf26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([[-0.8022, -0.6757, -0.9220, -2.5183],\n",
            "        [-0.2200, -0.2490,  2.2742, -0.1277],\n",
            "        [ 0.9367, -0.3330,  0.5704,  0.2867],\n",
            "        [ 0.6145,  0.8570, -1.2996, -0.2825]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd3WhxCz3Nmk"
      },
      "source": [
        "### torch.reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38EaRsiCycKK",
        "outputId": "32afdbf0-6cdf-4f75-92d2-7e0d030c26ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orginal tensor shape:  torch.Size([3, 4, 5])\n",
            "Orginal tensor: \n",
            "tensor([[[57, 34, 15, 17, 13],\n",
            "         [28, 26, 31, 40, 81],\n",
            "         [33, 86, 92, 59, 78],\n",
            "         [23, 63, 26,  6, 65]],\n",
            "\n",
            "        [[61, 21, 97, 95, 19],\n",
            "         [93, 28, 82, 62,  2],\n",
            "         [43, 92, 23, 93, 10],\n",
            "         [92, 82, 28, 17, 58]],\n",
            "\n",
            "        [[26, 29, 63, 48,  6],\n",
            "         [84, 17, 12, 72,  5],\n",
            "         [47, 45, 18, 15, 41],\n",
            "         [43, 13, 68, 33, 91]]])\n",
            "\n",
            "\n",
            "----------------\n",
            "Shape to have 12 rows and 5 columns (x.reshape((12,5))): \n",
            "\n",
            "tensor([[57, 34, 15, 17, 13],\n",
            "        [28, 26, 31, 40, 81],\n",
            "        [33, 86, 92, 59, 78],\n",
            "        [23, 63, 26,  6, 65],\n",
            "        [61, 21, 97, 95, 19],\n",
            "        [93, 28, 82, 62,  2],\n",
            "        [43, 92, 23, 93, 10],\n",
            "        [92, 82, 28, 17, 58],\n",
            "        [26, 29, 63, 48,  6],\n",
            "        [84, 17, 12, 72,  5],\n",
            "        [47, 45, 18, 15, 41],\n",
            "        [43, 13, 68, 33, 91]]) torch.Size([12, 5])\n",
            "\n",
            "\n",
            "----------------\n",
            "Shape to have 10 rows and using -1 to infer based on the elements in other dimensions (x.reshape(10,-1)): \n",
            "\n",
            "tensor([[57, 34, 15, 17, 13, 28],\n",
            "        [26, 31, 40, 81, 33, 86],\n",
            "        [92, 59, 78, 23, 63, 26],\n",
            "        [ 6, 65, 61, 21, 97, 95],\n",
            "        [19, 93, 28, 82, 62,  2],\n",
            "        [43, 92, 23, 93, 10, 92],\n",
            "        [82, 28, 17, 58, 26, 29],\n",
            "        [63, 48,  6, 84, 17, 12],\n",
            "        [72,  5, 47, 45, 18, 15],\n",
            "        [41, 43, 13, 68, 33, 91]]) torch.Size([10, 6])\n",
            "----------------\n",
            "\n",
            "\n",
            "Reshape to have 4 rows and 3 columns (x.reshape(5,4,3)): \n",
            "\n",
            "tensor([[[57, 34, 15],\n",
            "         [17, 13, 28],\n",
            "         [26, 31, 40],\n",
            "         [81, 33, 86]],\n",
            "\n",
            "        [[92, 59, 78],\n",
            "         [23, 63, 26],\n",
            "         [ 6, 65, 61],\n",
            "         [21, 97, 95]],\n",
            "\n",
            "        [[19, 93, 28],\n",
            "         [82, 62,  2],\n",
            "         [43, 92, 23],\n",
            "         [93, 10, 92]],\n",
            "\n",
            "        [[82, 28, 17],\n",
            "         [58, 26, 29],\n",
            "         [63, 48,  6],\n",
            "         [84, 17, 12]],\n",
            "\n",
            "        [[72,  5, 47],\n",
            "         [45, 18, 15],\n",
            "         [41, 43, 13],\n",
            "         [68, 33, 91]]]) torch.Size([5, 4, 3])\n",
            "\n",
            "\n",
            "----------------\n",
            "Reshape to single dimension (x.reshape(-1))\n",
            "\n",
            "tensor([57, 34, 15, 17, 13, 28, 26, 31, 40, 81, 33, 86, 92, 59, 78, 23, 63, 26,\n",
            "         6, 65, 61, 21, 97, 95, 19, 93, 28, 82, 62,  2, 43, 92, 23, 93, 10, 92,\n",
            "        82, 28, 17, 58, 26, 29, 63, 48,  6, 84, 17, 12, 72,  5, 47, 45, 18, 15,\n",
            "        41, 43, 13, 68, 33, 91]) torch.Size([60])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randint(0,100,size=(3,4,5))\n",
        "print('Orginal tensor shape: ', x.shape)\n",
        "print('Orginal tensor: ')\n",
        "print(x)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Shape to have 12 rows and 5 columns (x.reshape((12,5))): \\n')\n",
        "print(x.reshape((12,5)), x.reshape((12,5)).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Shape to have 10 rows and using -1 to infer based on the elements in other dimensions (x.reshape(10,-1)): \\n')\n",
        "print(x.reshape(10,-1), x.reshape(10,-1).shape) # Can use -1 to specify one of the dimensions which is automatically inferred based on the elements in other dimensions\n",
        "print(\"----------------\")\n",
        "print('\\n')\n",
        "print('Reshape to have 4 rows and 3 columns (x.reshape(5,4,3)): \\n')\n",
        "print(x.reshape(5,4,3), x.reshape(5,4,3).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Reshape to single dimension (x.reshape(-1))\\n')\n",
        "print(x.reshape(-1), x.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnORYt7VyVNz"
      },
      "source": [
        "## Get the value as a Python number from a one element tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzaKj9r0yXN0",
        "outputId": "0d52d8b9-3b86-49f1-e0c0-652214e40f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0644])\n",
            "-0.06439923495054245\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7sb67gbuGR2"
      },
      "source": [
        "## Multidimensional tensors can be changed to singe dimension with Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn-tVIG8uFp5",
        "outputId": "80dc42a2-5a80-447e-dd88-fcfd5559dbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 8, 15,  1, 10,  0],\n",
            "         [17,  7, 13, 17, 10],\n",
            "         [ 7,  5,  1,  8,  5],\n",
            "         [13, 12,  8, 18,  1]],\n",
            "\n",
            "        [[14,  2,  7,  3,  0],\n",
            "         [ 5,  7,  7,  2,  8],\n",
            "         [15,  7, 19,  9, 11],\n",
            "         [ 0,  4, 16,  6,  4]],\n",
            "\n",
            "        [[17,  6, 17, 17,  3],\n",
            "         [14,  0,  6,  7,  3],\n",
            "         [19,  9,  9, 17,  9],\n",
            "         [ 7, 12,  6, 19, 18]]])\n",
            "torch.Size([3, 4, 5])\n",
            "tensor([ 8, 15,  1, 10,  0, 17,  7, 13, 17, 10,  7,  5,  1,  8,  5, 13, 12,  8,\n",
            "        18,  1, 14,  2,  7,  3,  0,  5,  7,  7,  2,  8, 15,  7, 19,  9, 11,  0,\n",
            "         4, 16,  6,  4, 17,  6, 17, 17,  3, 14,  0,  6,  7,  3, 19,  9,  9, 17,\n",
            "         9,  7, 12,  6, 19, 18])\n",
            "torch.Size([60])\n"
          ]
        }
      ],
      "source": [
        "#x = torch.rand(size=(3,4,5)) # 3D tensor\n",
        "x = torch.randint(0,20,size=(3,4,5))  # 3D tensor\n",
        "print(x)\n",
        "print(x.shape)               # 3x4x5\n",
        "print(x.flatten())\n",
        "print(x.flatten().shape)     # 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBSAnT-suf3Y"
      },
      "source": [
        "##Dimensions can be added or removed with squeeze and unsqueeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km6mtJCL099t"
      },
      "source": [
        "   ### Add dimension with unsequeeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S0fVtyuucwO",
        "outputId": "f33b0976-a988-4b6b-9d99-501b0b8e192e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[12, 17,  0, 16, 11],\n",
            "          [19, 13, 19,  1,  1],\n",
            "          [16,  6, 14, 16,  7],\n",
            "          [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "         [[19, 16,  2, 17, 11],\n",
            "          [19, 13,  5,  9,  7],\n",
            "          [ 0,  8, 10, 13,  4],\n",
            "          [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "         [[ 9, 10,  6, 10, 14],\n",
            "          [ 5, 12,  6,  7,  8],\n",
            "          [11, 15, 19,  1, 11],\n",
            "          [ 4,  3,  9,  0, 19]]]])\n",
            "\n",
            "\n",
            "Original tensor shape torch.Size([3, 4, 5])\n",
            "Unsequeeze along axis 0 (xs=x.unsqueeze(dim=0)) torch.Size([1, 3, 4, 5])\n",
            "\n",
            "\n",
            "tensor([[[[[12, 17,  0, 16, 11],\n",
            "           [19, 13, 19,  1,  1],\n",
            "           [16,  6, 14, 16,  7],\n",
            "           [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "          [[19, 16,  2, 17, 11],\n",
            "           [19, 13,  5,  9,  7],\n",
            "           [ 0,  8, 10, 13,  4],\n",
            "           [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "          [[ 9, 10,  6, 10, 14],\n",
            "           [ 5, 12,  6,  7,  8],\n",
            "           [11, 15, 19,  1, 11],\n",
            "           [ 4,  3,  9,  0, 19]]]]])\n",
            "Unsequeeze along axis 0 a second time (xs.unsqueeze(0).shape): torch.Size([1, 1, 3, 4, 5])\n",
            "\n",
            "\n",
            "---------\n",
            "\n",
            "\n",
            "\n",
            "Original tensor\n",
            "\n",
            "tensor([[[12, 17,  0, 16, 11],\n",
            "         [19, 13, 19,  1,  1],\n",
            "         [16,  6, 14, 16,  7],\n",
            "         [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "        [[19, 16,  2, 17, 11],\n",
            "         [19, 13,  5,  9,  7],\n",
            "         [ 0,  8, 10, 13,  4],\n",
            "         [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "        [[ 9, 10,  6, 10, 14],\n",
            "         [ 5, 12,  6,  7,  8],\n",
            "         [11, 15, 19,  1, 11],\n",
            "         [ 4,  3,  9,  0, 19]]])\n",
            "Unsequeeze along axis 1 (x.unsqueeze(1)) :  torch.Size([3, 1, 4, 5])\n",
            "tensor([[[[12, 17,  0, 16, 11],\n",
            "          [19, 13, 19,  1,  1],\n",
            "          [16,  6, 14, 16,  7],\n",
            "          [ 0, 15,  8,  9,  0]]],\n",
            "\n",
            "\n",
            "        [[[19, 16,  2, 17, 11],\n",
            "          [19, 13,  5,  9,  7],\n",
            "          [ 0,  8, 10, 13,  4],\n",
            "          [ 9,  9,  7,  3, 12]]],\n",
            "\n",
            "\n",
            "        [[[ 9, 10,  6, 10, 14],\n",
            "          [ 5, 12,  6,  7,  8],\n",
            "          [11, 15, 19,  1, 11],\n",
            "          [ 4,  3,  9,  0, 19]]]])\n",
            "\n",
            "\n",
            "torch.Size([3, 4, 1, 5])\n",
            "Unsequeeze along axis 2 (x.unsqueeze(2)) :  torch.Size([3, 4, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "#x = torch.rand(size=(3,4,5))\n",
        "x = torch.randint(0,20,size=(3,4,5))\n",
        "xs = x.unsqueeze(dim=0)   # unsequeeze along axis 0\n",
        "xs2 = x.unsqueeze(1)  # unsequeeze along axis 1\n",
        "\n",
        "print(xs) # A new dimension is added while all the following dimension are incremented by 1 ( positionally)\n",
        "print('\\n')\n",
        "print('Original tensor shape',x.shape)\n",
        "print('Unsequeeze along axis 0 (xs=x.unsqueeze(dim=0))',xs.shape)\n",
        "print('\\n')\n",
        "\n",
        "print(xs.unsqueeze(0)) # Can apply this operation as many times as required\n",
        "print('Unsequeeze along axis 0 a second time (xs.unsqueeze(0).shape):',xs.unsqueeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"---------\\n\")\n",
        "print('\\n')\n",
        "print('Original tensor\\n')\n",
        "print(x)\n",
        "print('Unsequeeze along axis 1 (x.unsqueeze(1)) : ',xs2.shape)\n",
        "\n",
        "print(xs2) # Unsqueeze can also be applied to other intermediate dimensions\n",
        "print('\\n')\n",
        "xs3=x.unsqueeze(2)\n",
        "print(xs3.shape)\n",
        "print('Unsequeeze along axis 2 (x.unsqueeze(2)) : ',xs3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6MGPQ6Zxk2M"
      },
      "source": [
        "### Remove dimension with sequeeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfDx9SZBxfc-",
        "outputId": "8305dde2-6a7c-43a7-c737-6a72b1c3c70e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xs.shape :  torch.Size([1, 3, 4, 5])\n",
            "Original tensor xs\n",
            "\n",
            "tensor([[[[12, 17,  0, 16, 11],\n",
            "          [19, 13, 19,  1,  1],\n",
            "          [16,  6, 14, 16,  7],\n",
            "          [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "         [[19, 16,  2, 17, 11],\n",
            "          [19, 13,  5,  9,  7],\n",
            "          [ 0,  8, 10, 13,  4],\n",
            "          [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "         [[ 9, 10,  6, 10, 14],\n",
            "          [ 5, 12,  6,  7,  8],\n",
            "          [11, 15, 19,  1, 11],\n",
            "          [ 4,  3,  9,  0, 19]]]])\n",
            "sequeze axis 0 xs.squeeze(0)\n",
            "tensor([[[12, 17,  0, 16, 11],\n",
            "         [19, 13, 19,  1,  1],\n",
            "         [16,  6, 14, 16,  7],\n",
            "         [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "        [[19, 16,  2, 17, 11],\n",
            "         [19, 13,  5,  9,  7],\n",
            "         [ 0,  8, 10, 13,  4],\n",
            "         [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "        [[ 9, 10,  6, 10, 14],\n",
            "         [ 5, 12,  6,  7,  8],\n",
            "         [11, 15, 19,  1, 11],\n",
            "         [ 4,  3,  9,  0, 19]]])\n",
            "xs.squeeze(0).shape: torch.Size([3, 4, 5])\n",
            "\n",
            "\n",
            "-------------\n",
            "xs2.shape :  torch.Size([3, 1, 4, 5])\n",
            "Original tensor xs2\n",
            "\n",
            "tensor([[[[12, 17,  0, 16, 11],\n",
            "          [19, 13, 19,  1,  1],\n",
            "          [16,  6, 14, 16,  7],\n",
            "          [ 0, 15,  8,  9,  0]]],\n",
            "\n",
            "\n",
            "        [[[19, 16,  2, 17, 11],\n",
            "          [19, 13,  5,  9,  7],\n",
            "          [ 0,  8, 10, 13,  4],\n",
            "          [ 9,  9,  7,  3, 12]]],\n",
            "\n",
            "\n",
            "        [[[ 9, 10,  6, 10, 14],\n",
            "          [ 5, 12,  6,  7,  8],\n",
            "          [11, 15, 19,  1, 11],\n",
            "          [ 4,  3,  9,  0, 19]]]])\n",
            "sequeze axis 1 with xs2.squeeze(1)\n",
            "tensor([[[12, 17,  0, 16, 11],\n",
            "         [19, 13, 19,  1,  1],\n",
            "         [16,  6, 14, 16,  7],\n",
            "         [ 0, 15,  8,  9,  0]],\n",
            "\n",
            "        [[19, 16,  2, 17, 11],\n",
            "         [19, 13,  5,  9,  7],\n",
            "         [ 0,  8, 10, 13,  4],\n",
            "         [ 9,  9,  7,  3, 12]],\n",
            "\n",
            "        [[ 9, 10,  6, 10, 14],\n",
            "         [ 5, 12,  6,  7,  8],\n",
            "         [11, 15, 19,  1, 11],\n",
            "         [ 4,  3,  9,  0, 19]]])\n",
            "xs2.squeeze(1).shape: torch.Size([3, 4, 5])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"xs.shape : \",xs.shape)\n",
        "print('Original tensor xs\\n')\n",
        "print(xs)\n",
        "print(\"sequeze axis 0 xs.squeeze(0)\")\n",
        "print(xs.squeeze(0))\n",
        "print('xs.squeeze(0).shape:',xs.squeeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"-------------\")\n",
        "print(\"xs2.shape : \",xs2.shape)\n",
        "print('Original tensor xs2\\n')\n",
        "print(xs2)\n",
        "print(\"sequeze axis 1 with xs2.squeeze(1)\")\n",
        "print(xs2.squeeze(1))\n",
        "print('xs2.squeeze(1).shape:',xs2.squeeze(1).shape)\n",
        "print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCSFLA8F_MY4"
      },
      "source": [
        "## Combining Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKUUkpOq3tFg"
      },
      "source": [
        "### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC5MoIYd24r0",
        "outputId": "219d45cc-1f3d-48ed-8e95-59bd6403d742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x1:\n",
            " tensor([[[9, 5, 9, 1],\n",
            "         [9, 3, 5, 7],\n",
            "         [4, 4, 5, 6]],\n",
            "\n",
            "        [[2, 3, 4, 3],\n",
            "         [1, 1, 1, 5],\n",
            "         [1, 0, 3, 4]]]) \n",
            "\n",
            "x2:\n",
            " tensor([[[0, 7, 3, 3],\n",
            "         [2, 1, 6, 5],\n",
            "         [6, 1, 4, 7]],\n",
            "\n",
            "        [[7, 8, 0, 8],\n",
            "         [0, 7, 5, 5],\n",
            "         [5, 7, 1, 1]]]) \n",
            "\n",
            "CONCATENATING TENSORS\n",
            "\n",
            "Concatenating two tensors along axis 1 (torch.cat([x1,x2],dim=1))\n",
            "tensor([[[9, 5, 9, 1],\n",
            "         [9, 3, 5, 7],\n",
            "         [4, 4, 5, 6],\n",
            "         [0, 7, 3, 3],\n",
            "         [2, 1, 6, 5],\n",
            "         [6, 1, 4, 7]],\n",
            "\n",
            "        [[2, 3, 4, 3],\n",
            "         [1, 1, 1, 5],\n",
            "         [1, 0, 3, 4],\n",
            "         [7, 8, 0, 8],\n",
            "         [0, 7, 5, 5],\n",
            "         [5, 7, 1, 1]]])\n",
            "New Shape:  torch.Size([2, 6, 4])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.randint(0,10,size=(2,3,4))\n",
        "x2 = torch.randint(0,10,size=(2,3,4))\n",
        "\n",
        "print('x1:\\n', x1, \"\\n\")\n",
        "print('x2:\\n', x2, \"\\n\")\n",
        "\n",
        "print('CONCATENATING TENSORS\\n')\n",
        "\n",
        "print('Concatenating two tensors along axis 1 (torch.cat([x1,x2],dim=1))')\n",
        "print(torch.cat([x1,x2],dim=1))\n",
        "print('New Shape: ', torch.cat([x1,x2],dim=1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfllpE4D4Whb",
        "outputId": "bc280866-5ee2-4eda-f0b4-d89db9b7c727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Concatenating three tensors (x1,x2,x3) along axis 0\n",
            "\n",
            "x1 shape (2,3,4) : \n",
            " tensor([[[9, 5, 9, 1],\n",
            "         [9, 3, 5, 7],\n",
            "         [4, 4, 5, 6]],\n",
            "\n",
            "        [[2, 3, 4, 3],\n",
            "         [1, 1, 1, 5],\n",
            "         [1, 0, 3, 4]]]) \n",
            "\n",
            "x2 shape (2,3,4) : \n",
            " tensor([[[0, 7, 3, 3],\n",
            "         [2, 1, 6, 5],\n",
            "         [6, 1, 4, 7]],\n",
            "\n",
            "        [[7, 8, 0, 8],\n",
            "         [0, 7, 5, 5],\n",
            "         [5, 7, 1, 1]]]) \n",
            "\n",
            "x3 (size=(1,3,4)):\n",
            " tensor([[[1, 9, 2, 2],\n",
            "         [9, 5, 6, 5],\n",
            "         [0, 6, 2, 2]]]) \n",
            "\n",
            "Concatenate with torch.cat([x1,x2,x3],dim=0)\n",
            "tensor([[[9, 5, 9, 1],\n",
            "         [9, 3, 5, 7],\n",
            "         [4, 4, 5, 6]],\n",
            "\n",
            "        [[2, 3, 4, 3],\n",
            "         [1, 1, 1, 5],\n",
            "         [1, 0, 3, 4]],\n",
            "\n",
            "        [[0, 7, 3, 3],\n",
            "         [2, 1, 6, 5],\n",
            "         [6, 1, 4, 7]],\n",
            "\n",
            "        [[7, 8, 0, 8],\n",
            "         [0, 7, 5, 5],\n",
            "         [5, 7, 1, 1]],\n",
            "\n",
            "        [[1, 9, 2, 2],\n",
            "         [9, 5, 6, 5],\n",
            "         [0, 6, 2, 2]]])\n",
            "New Shape:  torch.Size([5, 3, 4])\n",
            "---------------------------\n",
            "\n",
            "Concatenating three tensors (x1,x2,x4) along axis 2\n",
            "\n",
            "x1 shape (2,3,4) : \n",
            " tensor([[[9, 5, 9, 1],\n",
            "         [9, 3, 5, 7],\n",
            "         [4, 4, 5, 6]],\n",
            "\n",
            "        [[2, 3, 4, 3],\n",
            "         [1, 1, 1, 5],\n",
            "         [1, 0, 3, 4]]]) \n",
            "\n",
            "x2 shape (2,3,4) : \n",
            " tensor([[[0, 7, 3, 3],\n",
            "         [2, 1, 6, 5],\n",
            "         [6, 1, 4, 7]],\n",
            "\n",
            "        [[7, 8, 0, 8],\n",
            "         [0, 7, 5, 5],\n",
            "         [5, 7, 1, 1]]]) \n",
            "\n",
            "x4 (size=(2,3,1)):\n",
            " tensor([[[9],\n",
            "         [6],\n",
            "         [5]],\n",
            "\n",
            "        [[9],\n",
            "         [4],\n",
            "         [9]]]) \n",
            "\n",
            "Concatenate with torch.cat([x1,x2,x4],dim=2)\n",
            "tensor([[[9, 5, 9, 1, 0, 7, 3, 3, 9],\n",
            "         [9, 3, 5, 7, 2, 1, 6, 5, 6],\n",
            "         [4, 4, 5, 6, 6, 1, 4, 7, 5]],\n",
            "\n",
            "        [[2, 3, 4, 3, 7, 8, 0, 8, 9],\n",
            "         [1, 1, 1, 5, 0, 7, 5, 5, 4],\n",
            "         [1, 0, 3, 4, 5, 7, 1, 1, 9]]])\n",
            "New Shape:  torch.Size([2, 3, 9])\n"
          ]
        }
      ],
      "source": [
        "# x1 shape (2,3,4)\n",
        "# x2 shape (2,3,4)\n",
        "\n",
        "x3 = torch.randint(0,10,size=(1,3,4))\n",
        "x4 = torch.randint(0,10,size=(2,3,1))\n",
        "print('\\nConcatenating three tensors (x1,x2,x3) along axis 0\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x3 (size=(1,3,4)):\\n', x3, \"\\n\")\n",
        "print('Concatenate with torch.cat([x1,x2,x3],dim=0)')\n",
        "print(torch.cat([x1,x2,x3],dim=0))\n",
        "print('New Shape: ', torch.cat([x1,x2,x3],dim=0).shape)\n",
        "print(\"---------------------------\")\n",
        "print('\\nConcatenating three tensors (x1,x2,x4) along axis 2\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x4 (size=(2,3,1)):\\n', x4, \"\\n\")\n",
        "\n",
        "print('Concatenate with torch.cat([x1,x2,x4],dim=2)')\n",
        "print(torch.cat([x1,x2,x4],dim=2))\n",
        "print('New Shape: ', torch.cat([x1,x2,x4],dim=2).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyo1lMzY6wBc"
      },
      "source": [
        "### Stacking (similar to a combination of unsqueeze and cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtNmg-aq6x7V",
        "outputId": "58b8f76a-e4fa-4027-f898-4eaa6e80a5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x1: \n",
            "\n",
            "torch.Size([3, 4])\n",
            "tensor([[2, 1, 7, 3],\n",
            "        [6, 2, 6, 7],\n",
            "        [3, 7, 1, 6]])\n",
            "\n",
            "\n",
            "x2: \n",
            "\n",
            "torch.Size([3, 4])\n",
            "tensor([[1, 1, 8, 5],\n",
            "        [1, 7, 6, 6],\n",
            "        [8, 9, 5, 7]])\n",
            "\n",
            "\n",
            "stack x1 and x2 at dim=0 : (3, 4) --> (1, 3, 4) --> (N, 3, 4) \n",
            "\n",
            "tensor([[[2, 1, 7, 3],\n",
            "         [6, 2, 6, 7],\n",
            "         [3, 7, 1, 6]],\n",
            "\n",
            "        [[1, 1, 8, 5],\n",
            "         [1, 7, 6, 6],\n",
            "         [8, 9, 5, 7]]])\n",
            "New Shape: torch.Size([2, 3, 4]) \n",
            "\n",
            "stack x1 and x2 at dim=1: (3, 4) --> (3, 1, 4) --> (3, N, 4) \n",
            "\n",
            "tensor([[[2, 1, 7, 3],\n",
            "         [1, 1, 8, 5]],\n",
            "\n",
            "        [[6, 2, 6, 7],\n",
            "         [1, 7, 6, 6]],\n",
            "\n",
            "        [[3, 7, 1, 6],\n",
            "         [8, 9, 5, 7]]])\n",
            "New Shape: torch.Size([3, 2, 4]) \n",
            "\n",
            "stack x1 and x2 at dim=2: (3, 4) --> (3, 4, 1) --> (3, 4, N) \n",
            "\n",
            "tensor([[[2, 1],\n",
            "         [1, 1],\n",
            "         [7, 8],\n",
            "         [3, 5]],\n",
            "\n",
            "        [[6, 1],\n",
            "         [2, 7],\n",
            "         [6, 6],\n",
            "         [7, 6]],\n",
            "\n",
            "        [[3, 8],\n",
            "         [7, 9],\n",
            "         [1, 5],\n",
            "         [6, 7]]])\n",
            "New Shape: torch.Size([3, 4, 2]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.randint(0,10,size=(3,4))\n",
        "x2 = torch.randint(0,10,size=(3,4))\n",
        "print('x1: \\n')\n",
        "print(x1.shape)\n",
        "print(x1)\n",
        "print('\\n')\n",
        "print('x2: \\n')\n",
        "print(x2.shape)\n",
        "print(x2)\n",
        "print('\\n')\n",
        "\n",
        "print('stack x1 and x2 at dim=0 : (3, 4) --> (1, 3, 4) --> (N, 3, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=0)) #(3, 4) --> (1, 3, 4) --> (N, 3, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=0).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=1: (3, 4) --> (3, 1, 4) --> (3, N, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=1)) #(3, 4) --> (3, 1, 4) --> (3, N, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=1).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=2: (3, 4) --> (3, 4, 1) --> (3, 4, N) \\n')\n",
        "print(torch.stack([x1,x2],dim=2)) #(3, 4) --> (3, 4, 1) --> (3, 4, N)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=2).shape, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUnnbb5Z8PkH"
      },
      "source": [
        "### Tensor Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5e2VEI8McX",
        "outputId": "94c24b19-633d-47c0-a616-47578613875d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[100, 100, 100, 100, 100, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100,   1,   2,   3,   4, 100, 100],\n",
            "        [100, 100, 100, 100, 100, 100, 100],\n",
            "        [100, 100, 100, 100, 100, 100, 100]])\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.tensor([[1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4]])\n",
        "\n",
        "pad_left   = 1\n",
        "pad_right  = 2\n",
        "pad_top    = 1\n",
        "pad_bottom = 2\n",
        "\n",
        "x_pad = F.pad(x, (pad_left,pad_right,pad_top,pad_bottom), mode = 'constant', value=100)\n",
        "print(x_pad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584dHoKDzOc9"
      },
      "source": [
        "For 100+ Tensor operations you can visit;\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pnBBTc087ys"
      },
      "source": [
        "---\n",
        "# **Vector/Matrix operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaNLuHKAjnB"
      },
      "source": [
        "##Vector-Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma9WeU4lA0Hr",
        "outputId": "b28cd776-d20b-4799-da9c-64b2091a7deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3])\n",
            "tensor([-0.4336, -2.6253,  1.0661]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([3])\n",
            "tensor([ 2.0208, -2.3603,  1.3975]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([])\n",
            "tensor(6.8101)\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([])\n",
            "tensor(6.8101) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3)\n",
        "tensor2 = torch.randn(3)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yblHh9F7AyPj"
      },
      "source": [
        "##Vector-Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPo38Ku3ByfO",
        "outputId": "9df70caf-97c7-44d6-c65e-a97fbe30fd72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3, 4])\n",
            "tensor([[-1.2883e+00,  9.1244e-01,  9.7273e-01, -1.7405e-04],\n",
            "        [-5.3386e-01, -1.5661e+00, -1.2959e-01, -2.2628e-01],\n",
            "        [ 1.0671e+00, -1.6019e+00, -1.7743e-01,  7.7391e-01]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([4])\n",
            "tensor([-0.7652,  0.5058, -0.6918, -0.3538]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([3])\n",
            "tensor([ 0.7744, -0.2140, -1.7778])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([3])\n",
            "tensor([ 0.7744, -0.2140, -1.7778]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaGupG3FB-Io"
      },
      "source": [
        "##Matrix-Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUlBUKs5CHw4",
        "outputId": "e8995d7c-cffa-4548-9fbe-9ce9551cf84f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([3, 4])\n",
            "tensor([[ 0.5163,  0.2764, -1.1305, -0.2085],\n",
            "        [-0.2833, -2.6454,  0.5773,  0.6564],\n",
            "        [-0.6128, -2.1383, -1.2673,  1.5112]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([4, 5])\n",
            "tensor([[-0.6610,  0.0136,  0.3701, -0.8704, -0.0192],\n",
            "        [ 0.3709,  1.5266,  0.8897,  0.3874,  0.8364],\n",
            "        [-1.2603,  0.5701,  0.5986, -0.4067,  0.2587],\n",
            "        [-0.5116,  0.1493,  0.3428,  0.3538,  0.1500]]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([3, 5])\n",
            "tensor([[ 1.2927, -0.2466, -0.3111,  0.0437, -0.1024],\n",
            "        [-1.8575, -3.6152, -1.8880, -0.7808, -1.9594],\n",
            "        [ 0.4359, -3.7697, -2.3699,  0.7551, -1.8779]])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([3, 5])\n",
            "tensor([[ 1.2927, -0.2466, -0.3111,  0.0437, -0.1024],\n",
            "        [-1.8575, -3.6152, -1.8880, -0.7808, -1.9594],\n",
            "        [ 0.4359, -3.7697, -2.3699,  0.7551, -1.8779]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS248-PNCer2",
        "outputId": "c624f97b-98f1-43dc-8f39-51cd9d287a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1\n",
            "torch.Size([2, 3, 4])\n",
            "tensor([[[-0.1414,  1.7106,  0.5445,  0.7905],\n",
            "         [ 0.0515,  1.0755,  1.8221, -0.3635],\n",
            "         [-0.5135,  0.3283,  1.2494,  0.1969]],\n",
            "\n",
            "        [[-0.0187, -1.0929,  0.3202,  0.4637],\n",
            "         [ 2.0406, -1.1523,  0.3165, -0.3483],\n",
            "         [-1.6775, -0.5218, -1.0846,  0.7392]]]) \n",
            "\n",
            "tensor2\n",
            "torch.Size([2, 4, 5])\n",
            "tensor([[[-0.5661,  1.8292,  1.0139, -1.2372,  0.8174],\n",
            "         [-0.3250,  0.2236, -1.0459,  0.9256,  0.8515],\n",
            "         [-0.1161,  0.9950, -0.3822, -0.6383,  0.0479],\n",
            "         [ 1.2048,  0.0248,  1.7030,  0.2333,  0.1187]],\n",
            "\n",
            "        [[ 0.1242, -0.6556, -0.9921, -1.7065, -0.8637],\n",
            "         [ 0.3349, -0.0214,  0.7697,  0.1861,  0.6741],\n",
            "         [-0.6943, -0.9119,  1.5296,  1.2703,  0.6132],\n",
            "         [ 0.2227,  0.6640, -0.2839, -0.1319,  1.0843]]]) \n",
            "\n",
            "===========\n",
            "\n",
            "tensor1 @ tensor2\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[ 0.4132,  0.6852, -0.7945,  1.5953,  1.4609],\n",
            "         [-1.0283,  2.1387, -2.3880, -0.3162,  1.0020],\n",
            "         [ 0.2762,  0.3820, -1.0062,  0.1878, -0.0570]],\n",
            "\n",
            "        [[-0.4874,  0.0516, -0.4645,  0.1741, -0.0215],\n",
            "         [-0.4298, -1.8330, -2.3283, -3.2488, -2.7228],\n",
            "         [ 0.5347,  2.5908, -0.6063,  1.2903,  1.2335]]])\n",
            "\n",
            "\n",
            "torch.matmul(tensor1, tensor2)\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[ 0.4132,  0.6852, -0.7945,  1.5953,  1.4609],\n",
            "         [-1.0283,  2.1387, -2.3880, -0.3162,  1.0020],\n",
            "         [ 0.2762,  0.3820, -1.0062,  0.1878, -0.0570]],\n",
            "\n",
            "        [[-0.4874,  0.0516, -0.4645,  0.1741, -0.0215],\n",
            "         [-0.4298, -1.8330, -2.3283, -3.2488, -2.7228],\n",
            "         [ 0.5347,  2.5908, -0.6063,  1.2903,  1.2335]]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.randn(2, 3, 4)\n",
        "tensor2 = torch.randn(2, 4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-D5VGEzkG2"
      },
      "source": [
        "---\n",
        "# **Converting a Torch tensor to a NumPy array, and vice versa**\n",
        "\n",
        "Torch tensors and numpy arrays can be converted to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgdtmEgE0GH-",
        "outputId": "44627bb7-d2a6-4d16-96cc-371993078967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "#tensor to numpy\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "y = x.numpy()\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8hKRHxs1h_e",
        "outputId": "2e20bf2c-45d4-46c6-81b6-6e1006e54020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#numpy to tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skX8vcFY1CvO"
      },
      "source": [
        "If underlying memory locations is on CPU, changing one will change the other;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9t5ed_1OHT",
        "outputId": "bc49c2dd-4054-4183-c8d8-2c3104a333cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az4LUKuV1fvU",
        "outputId": "8bd79939-7e9c-4bb5-dbfa-9744a401d47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0T8AGbH12F-"
      },
      "source": [
        "---\n",
        "# **CUDA Tensors**\n",
        "\n",
        "Tensors can be moved onto any device using the `.to` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzWeMu4d2DKQ",
        "outputId": "7206d999-5368-43da-9e53-7ef1b077a4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3., 3.], device='cuda:0')\n",
            "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# run this cell only if CUDA is available\n",
        "# Use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SvvIGUYeN3"
      },
      "source": [
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCWblVgRAo6F"
      },
      "source": [
        "---\n",
        "# **`Autograd` Package**\n",
        "\n",
        "\n",
        "\n",
        "* Provides automatic differentiation for all operations on Tensors\n",
        "* A define-by-run framework (backprop is defined by how the code is run, and that every single iteration can be different)\n",
        "* If the attribute `.requires_grad`  of a tensor is set to as `True`, all opeations on the tensor will be tracked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CR2vt1lC6ee",
        "outputId": "422a0780-87b8-4d6e-aea5-e426a0cf7132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrmO-TZyDspo",
        "outputId": "585f9506-995b-4899-8940-bee47623a624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7ff89238ceb0>\n"
          ]
        }
      ],
      "source": [
        "#y was created as a result of an operation, so it has a grad_fn.\n",
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8uCi4ONDwjl",
        "outputId": "b40d1814-633e-4ba8-a7bc-b191c88c8157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIhuuDoxDoka",
        "outputId": "ec7adb1d-3ac6-4d3e-9c9b-b28c8d66d976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7ff95493eb60>\n"
          ]
        }
      ],
      "source": [
        "#change an existing tensorâ€™s requires_grad flag in-place\n",
        "\n",
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z05jRG-2DR12"
      },
      "source": [
        "* When the computation is finished, `.backward()` can be calle to compute all the gradients automatically (gadient will be accumulated into `.grad` attribute)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFM6_oJfEUej",
        "outputId": "4d177aa2-9c29-4391-fa82-428cc192ae45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "out.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGkAOH1YESUV"
      },
      "source": [
        "* You can also stop autograd from tracking history by wrapping the code block in with torch.no_grad():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLLP63igFIhG",
        "outputId": "c5b52001-75c8-41bc-fa75-41651efce063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1M_lELkFo6l"
      },
      "source": [
        "* For more infomation: https://pytorch.org/docs/stable/autograd.html#function\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHlkLJNCF0LJ"
      },
      "source": [
        "---\n",
        "# **Neural Networks (NN)**\n",
        "\n",
        "* NN can be construted with `torch.nn` package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "OSYPwdhtGc1o"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfJ_jUwRQ_qo"
      },
      "source": [
        "* nn depends on autograd to define models and differentiate them.\n",
        "* A typical training procedure for a neural network is as follows:\n",
        "\n",
        "    **i.** Define the neural network that has some learnable parameters (or weights).\n",
        "    \n",
        "    > The learnable parameters of a model are returned by net.parameters()\n",
        "\n",
        "  **ii.** Iterate over a dataset of inputs\n",
        "\n",
        "    **iii.** Process input through the network\n",
        "\n",
        "    **iv.** Compute the loss (how far is the output from being correct).\n",
        "\n",
        "    **v.** Propagate gradients back into the networkâ€™s parameters with loss.backward()\n",
        "\n",
        "    **vi.** Update the weights of the network.\n",
        "\n",
        "    > This can be performed by any of the various different update rules that are implemented in `torch.optim` package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttXXwJEqQNu3",
        "outputId": "13c20c91-733f-44f1-90d6-4e37722c248b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1000]) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "#CREATE INPUT, AND OUTPUT\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "print(x.size(), y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ro9m4BQlTW",
        "outputId": "d9c25c8d-ded3-4274-eecd-1b5d9fce65b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#DEFINE NN:\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    #ReLU: rectified linear unit, activation function\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5eLJut3RT4_",
        "outputId": "ba748abd-d726-43a7-b79e-c1fa11e7351e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lenght of learnable parameters:  4\n",
            "Size of the first parameter:  torch.Size([100, 1000])\n"
          ]
        }
      ],
      "source": [
        "#LEARNABLE PARAMETERS IN THE MODEL:\n",
        "params = list(model.parameters())\n",
        "print(\"Lenght of learnable parameters: \",len(params))\n",
        "print(\"Size of the first parameter: \", params[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4RmEFGaTEz-",
        "outputId": "41baf2e6-c638-4326-bef9-228254fd80d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function: MSELoss()\n"
          ]
        }
      ],
      "source": [
        "# WE WILL NEED A LOSS FUNCTION FOR STEP iv.\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "print(\"Loss function:\", loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLNQlNlbKNzl",
        "outputId": "1924cf21-d0b5-4471-a155-a6637f6044ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer:  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TO UPDATE WEIGHTS, LETS USE ADAM\n",
        "# THAT IS ALREAY IMPLEMENTED IN torch.optim\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Optimizer: \", optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIWsyb0zVzX3",
        "outputId": "2414532c-9ead-471f-9644-4fa394f9bef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99 55.393531799316406\n",
            "199 0.9513719081878662\n",
            "299 0.004962279926985502\n",
            "399 2.2120322682894766e-05\n",
            "499 8.729466571821831e-08\n"
          ]
        }
      ],
      "source": [
        " #TRAINING LOOP:\n",
        "for t in range(500):\n",
        "\n",
        "    # Forward pass:\n",
        "    # Feed input to the model\n",
        "    # and compute predicted.\n",
        "\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    #with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "\n",
        "\n",
        "    # and update the weights.\n",
        "\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwTP0YKMQ3pS"
      },
      "source": [
        "---\n",
        "# **Training an image classifier**\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
        "2. Define a Convolutional Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x_sKrxzRMTf"
      },
      "source": [
        "**1. Loading and normalizing CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJbcmsfRx-Ks",
        "outputId": "0ef07c29-e7e2-4489-96f7-aaf99308c3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:01<00:00, 105274036.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "########################################################################\n",
        "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1].\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-SVwefYRhBb"
      },
      "source": [
        "Let us show some of the training images, for fun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "68BrNCxURajK",
        "outputId": "d66644c8-b166-467c-ba07-f41b19c954ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horse  bird  deer  ship\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVwlDD03RvqN"
      },
      "source": [
        "**2. Define a Convolutional Neural Network**\n",
        "\n",
        "CNNs systematically apply learned filters to input images in order to\n",
        "create feature maps that summarize the presence of those features in the input.\n",
        "\n",
        "We will use Conv2d for convolution layers. It applies a 2D convolution over an input signal composed of several input planes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIcwpZBJVfyn"
      },
      "source": [
        "Conv2D input :\n",
        "\n",
        "N is the batch size, C is the number of channels, H is the height of input planes and W is width\n",
        "\n",
        "$(N,C_{in},H_{in},W_{in})$ or  $(C_{in},H_{in},W_{in})$\n",
        "\n",
        "Conv2D output:\n",
        "\n",
        "$H_{out} = \\frac{H_{in} + 2 * padding[0] - dilation[0]*(kernel_{-}size[0]-1)-1}{stride[0]} +1$\n",
        "\n",
        "$W_{out} = \\frac{W_{in} + 2 * padding[1] - dilation[1]*(kernel_{-}size[1]-1)-1}{stride[1]} +1$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiOITK9ovvn0",
        "outputId": "fcc551bd-75d9-4318-f494-7e0bf3514bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#if we use equation given above\n",
        "#input size:   32x32x3\n",
        "#After conv1   28x28x6\n",
        "#After pooling 14x14x6\n",
        "#After conv2   10x10x16\n",
        "#After pooling 5x5x16\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #takes 3-channel images, 6 output channels, 5x5 square convolution kernel\n",
        "        #initialize 6 5x5-kernels, each having a total of 3 channels\n",
        "        #color images of 32x32 pixels in size\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        #A limitation of the feature map output of convolutional\n",
        "        #layers is that they record the precise position of features\n",
        "        #in the input. This means that small movements in the\n",
        "        #position of the feature in the input image will result in a\n",
        "        #different feature map.This can happen with re-cropping, rotation,\n",
        "        #shifting, and other minor changes to the input image.\n",
        "        #A common approach to addressing this problem from signal\n",
        "        #processing is called down sampling. This is where a lower\n",
        "        #resolution version of an input signal is created that still\n",
        "        #contains the large or important structural elements.\n",
        "        #A more robust and common approach is to use a POOLING LAYER.\n",
        "        #A pooling layer is a new layer added\n",
        "        #after the convolutional layer.\n",
        "        #The pooling layer operates upon each feature map separately\n",
        "        #to create a new set of the same number of pooled feature maps.\n",
        "        #The size of the pooling operation or filter is smaller than the\n",
        "        #size of the feature map\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_A9GyQHaDOU"
      },
      "source": [
        "**3. Define a Loss function and optimizer**\n",
        "\n",
        "Letâ€™s use a Classification Cross-Entropy loss and  stochastic gradient descent (SGD) with momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9-bJcL9mMEN6"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI6WLMBeaX1q"
      },
      "source": [
        "**4. Train the network**\n",
        "\n",
        "We will loop over our data iterator, and feed the inputs to the network and optimize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpcFrIE8OBKF",
        "outputId": "e5a9ab97-bc7c-4b45-abc6-46e4eac96eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.242\n",
            "[1,  4000] loss: 1.869\n",
            "[1,  6000] loss: 1.683\n",
            "[1,  8000] loss: 1.584\n",
            "[1, 10000] loss: 1.518\n",
            "[1, 12000] loss: 1.477\n",
            "[2,  2000] loss: 1.384\n",
            "[2,  4000] loss: 1.347\n",
            "[2,  6000] loss: 1.311\n",
            "[2,  8000] loss: 1.310\n",
            "[2, 10000] loss: 1.285\n",
            "[2, 12000] loss: 1.267\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_lXZ-CawcU"
      },
      "source": [
        "**5. Test the network on the test data**\n",
        "\n",
        "We need to check if the network has learnt anything at all.\n",
        "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "First,  let us display an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yOFPvWQ-M7Ng",
        "outputId": "b0f15705-5537-4054-de98-d24887f3611c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12jmH6zbXKg"
      },
      "source": [
        "Now let us see what the neural network thinks these examples above are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "achD24npNJs3",
        "outputId": "de734c86-9462-48f8-bb86-73daa5f9a31b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted:    cat  ship  ship plane\n"
          ]
        }
      ],
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJEccRoEb5tX"
      },
      "source": [
        "The results seem pretty good. Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5c8qpdWbv7i",
        "outputId": "5c91d751-8369-4ced-d623-789a182fdf93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 55 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nndl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
